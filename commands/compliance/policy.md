# /compliance:policy

Define governance policies for AI systems, aligned to EU AI Act and ISO/IEC 42001.

## Arguments
- org_name: organization or business unit
- scope: systems, products, or domains covered
- risk_appetite: high-level risk tolerance
- jurisdiction: applicable legal jurisdictions
- governance_model: committees, roles, and ownership
- lifecycle: development, deployment, monitoring
- enforcement: review cadence and approval gates

## Policy Set
- AI governance policy
- Risk management policy
- Data governance policy
- Model development and validation policy
- Transparency and user disclosure policy
- Human oversight policy
- Security and incident response policy
- Third-party/vendor policy
- Post-market monitoring policy

## Process
1. Stakeholder alignment and scope
2. Regulatory baseline and obligations
3. Policy drafting and review
4. Controls and KPIs definition
5. Approval workflow
6. Rollout and training
7. Monitoring and continuous improvement

## Policy Template
- Policy title:
- Purpose:
- Scope:
- Definitions:
- Roles and responsibilities:
- Required controls:
- Evidence and documentation:
- Exceptions and waivers:
- Enforcement and escalation:
- Review cadence:

## Control Mapping Template
- Control ID:
- Policy reference:
- EU AI Act requirement:
- ISO/IEC 42001 clause:
- Owner:
- Evidence:

## Governance Roles (Example)
- AI governance lead
- Risk manager
- DPO or privacy lead
- Security lead
- Model owner
- Product owner
- Legal counsel

## Security Agent Integration
- Include security agent in policy review for:
  - secure development lifecycle
  - vulnerability management
  - incident response and reporting
- Security agent provides:
  - control recommendations
  - security metrics
  - audit support

## Output Template
- Policy overview
- Defined roles and responsibilities
- Control mapping table
- Implementation plan
- Training and communication plan
