#!/bin/bash
# =============================================================================
# bin/tri-agent-supervisor
# =============================================================================
# M2-010: Unified Supervisor - Orchestrates Quality Gates & Approvals
# M2-011: Crash-Resistant Main Loop with Exponential Backoff
#
# Features:
# - Watches for tasks awaiting review
# - Runs unified workflow (gates + approve/reject)
# - Handles retries and permanent failures
# - Provides detailed logging and notifications
# - Crash-resistant main loop with error recovery
# - Exponential backoff on consecutive failures
# - Heartbeat signals for liveness monitoring
# - Graceful shutdown on SIGTERM/SIGINT
# - Auto-restart of internal components on failure
# =============================================================================

# NOTE: We intentionally do NOT use set -e here to enable crash-resistant behavior
# The main loop catches and handles all errors without exiting
set -uo pipefail

# Resolve paths
SCRIPT_PATH="${BASH_SOURCE[0]}"
while [[ -L "$SCRIPT_PATH" ]]; do
    SCRIPT_DIR="$(cd -P "$(dirname "$SCRIPT_PATH")" && pwd)"
    SCRIPT_PATH="$(readlink "$SCRIPT_PATH")"
    [[ "$SCRIPT_PATH" != /* ]] && SCRIPT_PATH="$SCRIPT_DIR/$SCRIPT_PATH"
done
SCRIPT_DIR="$(cd -P "$(dirname "$SCRIPT_PATH")" && pwd)"
AUTONOMOUS_ROOT="${AUTONOMOUS_ROOT:-$(cd "${SCRIPT_DIR}/.." && pwd)}"

source "${AUTONOMOUS_ROOT}/lib/common.sh"

# =============================================================================
# CONFIGURATION
# =============================================================================
REVIEW_DIR="${AUTONOMOUS_ROOT}/tasks/review"
APPROVED_DIR="${AUTONOMOUS_ROOT}/tasks/approved"
REJECTED_DIR="${AUTONOMOUS_ROOT}/tasks/rejected"
FAILED_DIR="${AUTONOMOUS_ROOT}/tasks/failed"
COMMS_DIR="${AUTONOMOUS_ROOT}/comms"
LOG_DIR="${AUTONOMOUS_ROOT}/logs/supervision"
STATE_DIR="${AUTONOMOUS_ROOT}/state"
SUPERVISOR_APPROVER="${AUTONOMOUS_ROOT}/lib/supervisor-approver.sh"

# DEP_REQUEST configuration (P0-5: Dependency Deadlock Resolution)
SUPERVISOR_INBOX="${STATE_DIR}/comms/supervisor/inbox"
WORKER_COMMS_DIR="${STATE_DIR}/comms/worker"
DEP_INSTALL_TIMEOUT="${DEP_INSTALL_TIMEOUT:-120}"
DEP_ALLOWED_TYPES=("npm" "pip" "pip3" "apt" "apt-get" "cargo")

# M2-011: Heartbeat and state files
HEARTBEAT_FILE="${STATE_DIR}/supervisor-heartbeat"
PID_FILE="${STATE_DIR}/supervisor.pid"
STATE_FILE="${STATE_DIR}/supervisor-state.json"

# Configurable settings
WATCH_INTERVAL="${WATCH_INTERVAL:-30}"
MAX_CONCURRENT="${MAX_CONCURRENT:-3}"
SINGLE_RUN="${SINGLE_RUN:-false}"
VERBOSE="${VERBOSE:-false}"

# M2-011: Backoff configuration
INITIAL_BACKOFF="${INITIAL_BACKOFF:-1}"           # Initial backoff in seconds
MAX_BACKOFF="${MAX_BACKOFF:-300}"                 # Maximum backoff (5 minutes)
BACKOFF_MULTIPLIER="${BACKOFF_MULTIPLIER:-2}"     # Exponential multiplier
HEARTBEAT_INTERVAL="${HEARTBEAT_INTERVAL:-10}"   # Heartbeat interval in seconds
MAX_CONSECUTIVE_FAILURES="${MAX_CONSECUTIVE_FAILURES:-10}"  # Max failures before extended backoff
COMPONENT_RESTART_DELAY="${COMPONENT_RESTART_DELAY:-5}"     # Delay before restarting components

# Counters for session statistics
declare -i TOTAL_PROCESSED=0
declare -i TOTAL_APPROVED=0
declare -i TOTAL_REJECTED=0
declare -i TOTAL_FAILED=0

# M2-011: Runtime state
declare -i CONSECUTIVE_FAILURES=0
declare -i CURRENT_BACKOFF=$INITIAL_BACKOFF
declare -i LAST_HEARTBEAT=0
declare -i CYCLE_COUNT=0
declare -i START_TIME=0
SHUTDOWN_REQUESTED=false
SUPERVISOR_STATE="starting"

# Ensure directories exist
mkdir -p "$REVIEW_DIR" "$APPROVED_DIR" "$REJECTED_DIR" "$FAILED_DIR" "$LOG_DIR" "$STATE_DIR" "$SUPERVISOR_INBOX" 2>/dev/null || true

# =============================================================================
# LOGGING
# =============================================================================
log_supervisor() {
    local level="$1"
    local message="$2"
    local timestamp
    timestamp=$(date -Iseconds)

    echo "[${timestamp}] [SUPERVISOR] [${level}] ${message}" >&2
    echo "[${timestamp}] [SUPERVISOR] [${level}] ${message}" >> "${LOG_DIR}/supervisor.log" 2>/dev/null || true
}

# =============================================================================
# P0-5: DEPENDENCY REQUEST HANDLING
# =============================================================================
# Handles DEP_REQUEST messages from workers requesting dependency installation.
# This prevents deadlocks where tasks fail repeatedly due to missing dependencies.
#
# Message Format (DEP_REQUEST):
#   {
#     "type": "DEP_REQUEST",
#     "request_id": "depreq_<task_id>_<timestamp>",
#     "task_id": "<task_id>",
#     "worker_id": "<worker_id>",
#     "dependency": {"type": "pip|npm|apt|cargo", "name": "<package>"},
#     "timestamp": "<ISO timestamp>",
#     "timeout_sec": <timeout>
#   }
#
# Response Format (DEP_RESPONSE):
#   {
#     "type": "DEP_RESPONSE",
#     "request_id": "<request_id>",
#     "status": "installed|failed",
#     "reason": "<reason if failed>",
#     "timestamp": "<ISO timestamp>"
#   }
# =============================================================================

# Validate dependency type is allowed
validate_dep_type() {
    local dep_type="$1"

    for allowed in "${DEP_ALLOWED_TYPES[@]}"; do
        if [[ "$dep_type" == "$allowed" ]]; then
            return 0
        fi
    done

    return 1
}

# Sanitize package name to prevent command injection
sanitize_package_name() {
    local name="$1"
    # Remove any characters that could be used for injection
    # Only allow alphanumeric, dash, underscore, dot, and @ (for scoped npm packages)
    echo "$name" | sed 's/[^a-zA-Z0-9._@/-]//g'
}

# Install a dependency using the appropriate package manager
install_dependency() {
    local dep_type="$1"
    local dep_name="$2"
    local timeout="${3:-$DEP_INSTALL_TIMEOUT}"

    # Sanitize package name
    local safe_name
    safe_name=$(sanitize_package_name "$dep_name")

    if [[ -z "$safe_name" ]]; then
        log_supervisor "ERROR" "Invalid package name after sanitization: $dep_name"
        return 1
    fi

    if [[ "$safe_name" != "$dep_name" ]]; then
        log_supervisor "WARN" "Package name sanitized: '$dep_name' -> '$safe_name'"
    fi

    log_supervisor "INFO" "Installing $dep_type package: $safe_name (timeout: ${timeout}s)"

    local install_cmd=""
    local result=0

    case "$dep_type" in
        npm)
            install_cmd="npm install -g $safe_name"
            ;;
        pip|pip3)
            install_cmd="$dep_type install --user $safe_name"
            ;;
        apt|apt-get)
            # apt requires sudo typically
            if command -v sudo &>/dev/null; then
                install_cmd="sudo $dep_type install -y $safe_name"
            else
                install_cmd="$dep_type install -y $safe_name"
            fi
            ;;
        cargo)
            install_cmd="cargo install $safe_name"
            ;;
        *)
            log_supervisor "ERROR" "Unknown dependency type: $dep_type"
            return 1
            ;;
    esac

    log_supervisor "DEBUG" "Running: $install_cmd"

    # Run with timeout
    if command -v timeout &>/dev/null; then
        if timeout "$timeout" bash -c "$install_cmd" >> "${LOG_DIR}/dep-install.log" 2>&1; then
            log_supervisor "INFO" "Successfully installed: $safe_name"
            return 0
        else
            result=$?
            if [[ $result -eq 124 ]]; then
                log_supervisor "ERROR" "Installation timed out after ${timeout}s: $safe_name"
            else
                log_supervisor "ERROR" "Installation failed (exit $result): $safe_name"
            fi
            return 1
        fi
    else
        # No timeout command, run directly
        if bash -c "$install_cmd" >> "${LOG_DIR}/dep-install.log" 2>&1; then
            log_supervisor "INFO" "Successfully installed: $safe_name"
            return 0
        else
            log_supervisor "ERROR" "Installation failed: $safe_name"
            return 1
        fi
    fi
}

# Send DEP_RESPONSE back to worker
send_dep_response() {
    local worker_id="$1"
    local request_id="$2"
    local status="$3"
    local reason="${4:-}"

    local response_dir="${WORKER_COMMS_DIR}/${worker_id}/inbox"
    local response_file="${response_dir}/${request_id}_response.json"

    mkdir -p "$response_dir" 2>/dev/null || true

    local timestamp
    timestamp=$(date -Iseconds)

    cat > "$response_file" <<EOF
{
    "type": "DEP_RESPONSE",
    "request_id": "$request_id",
    "status": "$status",
    "reason": "$reason",
    "timestamp": "$timestamp"
}
EOF

    log_supervisor "INFO" "DEP_RESPONSE sent to $worker_id: $status (request: $request_id)"
}

# Handle a single DEP_REQUEST
handle_dep_request() {
    local request_file="$1"

    if [[ ! -f "$request_file" ]]; then
        log_supervisor "WARN" "DEP_REQUEST file not found: $request_file"
        return 1
    fi

    # Parse the request JSON
    local request_id worker_id task_id dep_type dep_name timeout_sec

    if ! command -v jq &>/dev/null; then
        log_supervisor "ERROR" "jq not available for parsing DEP_REQUEST"
        rm -f "$request_file"
        return 1
    fi

    request_id=$(jq -r '.request_id // ""' "$request_file" 2>/dev/null)
    worker_id=$(jq -r '.worker_id // ""' "$request_file" 2>/dev/null)
    task_id=$(jq -r '.task_id // ""' "$request_file" 2>/dev/null)
    dep_type=$(jq -r '.dependency.type // ""' "$request_file" 2>/dev/null)
    dep_name=$(jq -r '.dependency.name // ""' "$request_file" 2>/dev/null)
    timeout_sec=$(jq -r '.timeout_sec // 120' "$request_file" 2>/dev/null)

    log_supervisor "INFO" "Processing DEP_REQUEST: $request_id (worker: $worker_id, type: $dep_type, name: $dep_name)"

    # Validate required fields
    if [[ -z "$request_id" || -z "$worker_id" || -z "$dep_type" || -z "$dep_name" ]]; then
        log_supervisor "ERROR" "Invalid DEP_REQUEST: missing required fields"
        if [[ -n "$worker_id" && -n "$request_id" ]]; then
            send_dep_response "$worker_id" "$request_id" "failed" "Invalid request: missing required fields"
        fi
        rm -f "$request_file"
        return 1
    fi

    # Validate dependency type
    if ! validate_dep_type "$dep_type"; then
        log_supervisor "ERROR" "Disallowed dependency type: $dep_type"
        send_dep_response "$worker_id" "$request_id" "failed" "Disallowed dependency type: $dep_type"
        rm -f "$request_file"
        return 1
    fi

    # Attempt installation
    local status="failed"
    local reason=""

    if install_dependency "$dep_type" "$dep_name" "$timeout_sec"; then
        status="installed"
        reason="Successfully installed $dep_name"
    else
        reason="Failed to install $dep_name via $dep_type"
    fi

    # Send response to worker
    send_dep_response "$worker_id" "$request_id" "$status" "$reason"

    # Remove the processed request
    rm -f "$request_file"

    if [[ "$status" == "installed" ]]; then
        return 0
    else
        return 1
    fi
}

# Check for and process pending DEP_REQUESTs
check_dep_requests() {
    local count=0
    local processed=0

    # Ensure inbox exists
    [[ -d "$SUPERVISOR_INBOX" ]] || return 0

    # Process all pending DEP_REQUEST files
    for request_file in "${SUPERVISOR_INBOX}"/*.json; do
        [[ -f "$request_file" ]] || continue

        # Check if this is a DEP_REQUEST
        local msg_type
        msg_type=$(jq -r '.type // ""' "$request_file" 2>/dev/null || echo "")

        if [[ "$msg_type" != "DEP_REQUEST" ]]; then
            [[ "$VERBOSE" == "true" ]] && log_supervisor "DEBUG" "Skipping non-DEP_REQUEST: $request_file"
            continue
        fi

        ((count++))

        # Check for shutdown between requests
        if [[ "$SHUTDOWN_REQUESTED" == "true" ]]; then
            log_supervisor "INFO" "Shutdown requested, stopping DEP_REQUEST processing"
            break
        fi

        if handle_dep_request "$request_file"; then
            ((processed++))
        fi
    done

    if (( count > 0 )); then
        log_supervisor "INFO" "DEP_REQUEST: processed $processed/$count dependency requests"
    fi

    return 0
}

# =============================================================================
# M2-011: HEARTBEAT SYSTEM
# =============================================================================
# Sends periodic heartbeat signals to indicate the supervisor is alive
# Other processes can monitor this file to detect supervisor health
# =============================================================================
send_heartbeat() {
    local now
    now=$(date +%s)

    # Only send heartbeat if interval has passed
    if (( now - LAST_HEARTBEAT >= HEARTBEAT_INTERVAL )); then
        local heartbeat_data
        heartbeat_data=$(cat <<EOF
{
  "timestamp": "$(date -Iseconds)",
  "epoch": $now,
  "pid": $$,
  "state": "$SUPERVISOR_STATE",
  "cycle_count": $CYCLE_COUNT,
  "uptime_seconds": $((now - START_TIME)),
  "consecutive_failures": $CONSECUTIVE_FAILURES,
  "current_backoff": $CURRENT_BACKOFF,
  "stats": {
    "processed": $TOTAL_PROCESSED,
    "approved": $TOTAL_APPROVED,
    "rejected": $TOTAL_REJECTED,
    "failed": $TOTAL_FAILED
  }
}
EOF
)
        echo "$heartbeat_data" > "$HEARTBEAT_FILE" 2>/dev/null || true
        LAST_HEARTBEAT=$now

        [[ "$VERBOSE" == "true" ]] && log_supervisor "DEBUG" "Heartbeat sent (cycle: $CYCLE_COUNT, failures: $CONSECUTIVE_FAILURES)"
    fi
}

# =============================================================================
# M2-011: STATE MANAGEMENT
# =============================================================================
# Persists supervisor state for recovery and monitoring
# =============================================================================
save_state() {
    local state_data
    state_data=$(cat <<EOF
{
  "timestamp": "$(date -Iseconds)",
  "pid": $$,
  "state": "$SUPERVISOR_STATE",
  "start_time": $START_TIME,
  "cycle_count": $CYCLE_COUNT,
  "consecutive_failures": $CONSECUTIVE_FAILURES,
  "current_backoff": $CURRENT_BACKOFF,
  "shutdown_requested": $SHUTDOWN_REQUESTED,
  "stats": {
    "processed": $TOTAL_PROCESSED,
    "approved": $TOTAL_APPROVED,
    "rejected": $TOTAL_REJECTED,
    "failed": $TOTAL_FAILED
  },
  "config": {
    "watch_interval": $WATCH_INTERVAL,
    "max_concurrent": $MAX_CONCURRENT,
    "max_backoff": $MAX_BACKOFF,
    "heartbeat_interval": $HEARTBEAT_INTERVAL
  }
}
EOF
)
    echo "$state_data" > "$STATE_FILE" 2>/dev/null || true
}

update_state() {
    local new_state="$1"
    SUPERVISOR_STATE="$new_state"
    save_state
    log_supervisor "INFO" "State changed to: $new_state"
}

# =============================================================================
# M2-011: EXPONENTIAL BACKOFF
# =============================================================================
# Implements exponential backoff on consecutive failures
# Resets backoff on successful cycle
# =============================================================================
calculate_backoff() {
    # Double the backoff on each failure, up to MAX_BACKOFF
    CURRENT_BACKOFF=$((CURRENT_BACKOFF * BACKOFF_MULTIPLIER))
    if (( CURRENT_BACKOFF > MAX_BACKOFF )); then
        CURRENT_BACKOFF=$MAX_BACKOFF
    fi
    log_supervisor "WARN" "Backoff increased to ${CURRENT_BACKOFF}s after $CONSECUTIVE_FAILURES consecutive failures"
}

reset_backoff() {
    if (( CONSECUTIVE_FAILURES > 0 )); then
        log_supervisor "INFO" "Resetting backoff after successful cycle (was: ${CURRENT_BACKOFF}s, failures: $CONSECUTIVE_FAILURES)"
    fi
    CONSECUTIVE_FAILURES=0
    CURRENT_BACKOFF=$INITIAL_BACKOFF
}

perform_backoff_sleep() {
    local sleep_time="$1"
    local elapsed=0

    log_supervisor "INFO" "Backing off for ${sleep_time}s (consecutive failures: $CONSECUTIVE_FAILURES)"

    # Sleep in small increments to remain responsive to signals
    while (( elapsed < sleep_time )) && [[ "$SHUTDOWN_REQUESTED" != "true" ]]; do
        local remaining=$((sleep_time - elapsed))
        local chunk=$((remaining < 5 ? remaining : 5))

        sleep "$chunk"
        elapsed=$((elapsed + chunk))

        # Send heartbeat during long backoffs
        send_heartbeat
    done
}

# =============================================================================
# M2-011: SIGNAL HANDLERS - GRACEFUL SHUTDOWN
# =============================================================================
# Handles SIGTERM and SIGINT for clean shutdown
# Allows current operations to complete before exiting
# =============================================================================
request_shutdown() {
    local signal="$1"
    log_supervisor "INFO" "Received $signal - initiating graceful shutdown"
    SHUTDOWN_REQUESTED=true
    update_state "shutting_down"
}

cleanup() {
    log_supervisor "INFO" "Supervisor shutting down (PID: $$)"
    update_state "stopped"

    # Remove PID file
    rm -f "$PID_FILE" 2>/dev/null || true

    # Final heartbeat
    send_heartbeat

    print_status
    exit 0
}

# Signal handlers are set up in run_daemon() only for daemon mode
# This prevents cleanup from running for status/help commands

# =============================================================================
# M2-011: COMPONENT HEALTH CHECK AND AUTO-RESTART
# =============================================================================
# Checks health of internal components and restarts them if needed
# =============================================================================
check_component_health() {
    local component="$1"
    local component_path="$2"

    case "$component" in
        supervisor-approver)
            if [[ ! -x "$component_path" ]]; then
                log_supervisor "ERROR" "Component not found or not executable: $component_path"
                return 1
            fi
            # Test component can be invoked (dry run)
            if ! "$component_path" --version &>/dev/null 2>&1; then
                # Component doesn't support --version, try help
                if ! "$component_path" help &>/dev/null 2>&1; then
                    log_supervisor "WARN" "Component $component may be unhealthy (cannot verify)"
                fi
            fi
            ;;
        *)
            log_supervisor "DEBUG" "Unknown component: $component"
            return 1
            ;;
    esac

    return 0
}

restart_component() {
    local component="$1"
    log_supervisor "WARN" "Attempting to restart component: $component"

    # Give component time to settle
    sleep "$COMPONENT_RESTART_DELAY"

    case "$component" in
        supervisor-approver)
            # No persistent process to restart, just verify it exists
            if [[ -x "$SUPERVISOR_APPROVER" ]]; then
                log_supervisor "INFO" "Component $component is available"
                return 0
            else
                log_supervisor "ERROR" "Component $component restart failed - not executable"
                return 1
            fi
            ;;
        *)
            log_supervisor "WARN" "Unknown component: $component"
            return 1
            ;;
    esac
}

# =============================================================================
# M2-010: UNIFIED REVIEW PROCESSING
# =============================================================================
# Processes a single task through the unified workflow
# Returns: 0 on approval, 1 on rejection, 2 on permanent failure
# =============================================================================
process_task() {
    local task_id="$1"
    local workspace="${2:-$AUTONOMOUS_ROOT}"

    log_supervisor "INFO" "Processing task: $task_id"

    # Verify supervisor-approver.sh exists
    if [[ ! -f "$SUPERVISOR_APPROVER" ]]; then
        log_supervisor "ERROR" "Supervisor approver not found: $SUPERVISOR_APPROVER"
        return 1
    fi

    # Call the unified workflow (library-first, CLI fallback)
    local result=0
    local output

    output=$(
        (
            set -euo pipefail
            source "$SUPERVISOR_APPROVER" || exit 96
            if ! declare -F unified_workflow >/dev/null 2>&1; then
                echo "Supervisor approver missing unified_workflow" >&2
                exit 97
            fi
            unified_workflow "$task_id" "$workspace"
        ) 2>&1
    ) || result=$?

    # Fallback to CLI invocation if library load failed
    if [[ $result -eq 96 || $result -eq 97 ]]; then
        log_supervisor "WARN" "Library workflow unavailable, falling back to CLI invocation"
        if [[ -x "$SUPERVISOR_APPROVER" ]]; then
            output=$("$SUPERVISOR_APPROVER" workflow "$task_id" "$workspace" 2>&1) || result=$?
        else
            log_supervisor "ERROR" "Supervisor approver not executable for CLI fallback: $SUPERVISOR_APPROVER"
            return 1
        fi
    fi

    # Log the output
    [[ "$VERBOSE" == "true" ]] && log_supervisor "DEBUG" "Workflow output: $output"

    case $result in
        0)
            log_supervisor "PASS" "Task $task_id APPROVED"
            ((TOTAL_APPROVED++))
            return 0
            ;;
        1)
            log_supervisor "WARN" "Task $task_id REJECTED (retryable)"
            ((TOTAL_REJECTED++))
            return 1
            ;;
        2)
            log_supervisor "FAIL" "Task $task_id PERMANENTLY FAILED"
            ((TOTAL_FAILED++))
            return 2
            ;;
        *)
            log_supervisor "ERROR" "Task $task_id unexpected result: $result"
            ((TOTAL_REJECTED++))
            return $result
            ;;
    esac
}

# =============================================================================
# REVIEW QUEUE CHECK
# =============================================================================
# Scans the review directory and processes pending tasks
# Returns: 0 on success (including no tasks), 1 on error
# =============================================================================
check_reviews() {
    local count=0
    local processed=0
    local errors=0

    # Count pending tasks
    for task_file in "${REVIEW_DIR}"/*.md; do
        [[ -f "$task_file" ]] || continue
        ((count++))
    done

    if [[ $count -eq 0 ]]; then
        [[ "$VERBOSE" == "true" ]] && log_supervisor "DEBUG" "No tasks awaiting review"
        return 0
    fi

    log_supervisor "INFO" "Found $count task(s) awaiting review"

    # Process each task
    for task_file in "${REVIEW_DIR}"/*.md; do
        [[ -f "$task_file" ]] || continue

        # Check for shutdown request between tasks
        if [[ "$SHUTDOWN_REQUESTED" == "true" ]]; then
            log_supervisor "INFO" "Shutdown requested, stopping task processing"
            break
        fi

        # Check concurrent limit
        if [[ $processed -ge $MAX_CONCURRENT ]]; then
            log_supervisor "INFO" "Reached concurrent limit ($MAX_CONCURRENT), pausing"
            break
        fi

        local task_id
        task_id=$(basename "$task_file" .md)

        # Skip hidden files
        [[ "$task_id" == .* ]] && continue

        log_supervisor "INFO" "------- Processing: $task_id -------"

        # Process the task with error handling
        local result=0
        if ! process_task "$task_id" "$AUTONOMOUS_ROOT"; then
            result=$?
            ((errors++))
        fi

        ((TOTAL_PROCESSED++))
        ((processed++))

        # Log result
        case $result in
            0) log_supervisor "INFO" "Task $task_id completed (APPROVED)" ;;
            1) log_supervisor "WARN" "Task $task_id completed (REJECTED)" ;;
            2) log_supervisor "ERROR" "Task $task_id completed (PERMANENT FAIL)" ;;
        esac

        log_supervisor "INFO" "------- End: $task_id -------"

        # Send heartbeat after each task
        send_heartbeat
    done

    log_supervisor "INFO" "Processed $processed tasks this cycle ($errors errors)"

    # Return error status if all tasks failed
    if (( processed > 0 && errors == processed )); then
        return 1
    fi

    return 0
}

# =============================================================================
# STATUS REPORT
# =============================================================================
print_status() {
    local now
    now=$(date +%s)
    local uptime=$((now - START_TIME))

    echo ""
    echo "=== Supervisor Session Statistics ==="
    echo "PID:             $$"
    echo "State:           $SUPERVISOR_STATE"
    echo "Uptime:          ${uptime}s"
    echo "Cycles:          $CYCLE_COUNT"
    echo ""
    echo "Processing Stats:"
    echo "  Processed:     $TOTAL_PROCESSED"
    echo "  Approved:      $TOTAL_APPROVED"
    echo "  Rejected:      $TOTAL_REJECTED"
    echo "  Failed:        $TOTAL_FAILED"
    echo ""
    echo "Health Stats:"
    echo "  Consecutive Failures: $CONSECUTIVE_FAILURES"
    echo "  Current Backoff:      ${CURRENT_BACKOFF}s"
    echo ""
    echo "Queues:"
    echo "  Review:    $(find "$REVIEW_DIR" -name "*.md" 2>/dev/null | wc -l) tasks"
    echo "  Approved:  $(find "$APPROVED_DIR" -name "*.md" 2>/dev/null | wc -l) tasks"
    echo "  Rejected:  $(find "$REJECTED_DIR" -name "*.md" 2>/dev/null | wc -l) tasks"
    echo "  Failed:    $(find "$FAILED_DIR" -name "*.md" 2>/dev/null | wc -l) tasks"
    echo "====================================="
}

# =============================================================================
# M2-011: CRASH-RESISTANT MAIN LOOP
# =============================================================================
# Implements a crash-resistant main loop that:
# 1. Catches all errors without crashing
# 2. Implements exponential backoff on consecutive failures
# 3. Sends heartbeat signals for liveness monitoring
# 4. Checks for shutdown signals between iterations
# 5. Auto-restarts components on failure
# =============================================================================
run_daemon() {
    START_TIME=$(date +%s)

    # Set up signal handlers for daemon mode
    trap 'request_shutdown "SIGTERM"' SIGTERM
    trap 'request_shutdown "SIGINT"' SIGINT
    trap cleanup EXIT

    # Write PID file
    echo $$ > "$PID_FILE"

    log_supervisor "INFO" "Starting Tri-Agent Supervisor (PID: $$)"
    log_supervisor "INFO" "Watch interval: ${WATCH_INTERVAL}s"
    log_supervisor "INFO" "Max concurrent: $MAX_CONCURRENT"
    log_supervisor "INFO" "Review directory: $REVIEW_DIR"
    log_supervisor "INFO" "Heartbeat interval: ${HEARTBEAT_INTERVAL}s"
    log_supervisor "INFO" "Max backoff: ${MAX_BACKOFF}s"
    log_supervisor "INFO" "DEP_REQUEST enabled: inbox=$SUPERVISOR_INBOX"

    update_state "running"
    send_heartbeat

    # Main crash-resistant loop
    while true; do
        # Check for shutdown request
        if [[ "$SHUTDOWN_REQUESTED" == "true" ]]; then
            log_supervisor "INFO" "Shutdown requested, exiting main loop"
            break
        fi

        ((CYCLE_COUNT++))
        local cycle_start
        cycle_start=$(date +%s)
        local cycle_success=true

        [[ "$VERBOSE" == "true" ]] && log_supervisor "DEBUG" "Starting cycle $CYCLE_COUNT"

        # P0-5: Check for DEP_REQUESTs from workers first
        # This allows workers to retry tasks after dependencies are installed
        {
            check_dep_requests
        } || {
            log_supervisor "WARN" "DEP_REQUEST processing failed (non-fatal)"
        }

        # Run check_reviews with comprehensive error handling
        # This is the core of the crash-resistant design
        {
            check_reviews
        } || {
            local error_code=$?
            cycle_success=false
            log_supervisor "ERROR" "Cycle $CYCLE_COUNT failed with error code: $error_code"

            # Check if we need to restart components
            if (( CONSECUTIVE_FAILURES > 0 && CONSECUTIVE_FAILURES % 3 == 0 )); then
                log_supervisor "WARN" "Multiple consecutive failures, checking component health"
                if ! check_component_health "supervisor-approver" "$SUPERVISOR_APPROVER"; then
                    restart_component "supervisor-approver"
                fi
            fi
        }

        # Update backoff based on cycle result
        if [[ "$cycle_success" == "true" ]]; then
            reset_backoff
        else
            ((CONSECUTIVE_FAILURES++))

            # Check if we've hit the failure threshold
            if (( CONSECUTIVE_FAILURES >= MAX_CONSECUTIVE_FAILURES )); then
                log_supervisor "ERROR" "Hit maximum consecutive failures ($MAX_CONSECUTIVE_FAILURES)"
                log_supervisor "WARN" "Entering extended backoff mode"
                update_state "degraded"
            fi

            calculate_backoff
        fi

        # Send heartbeat
        send_heartbeat
        save_state

        # Single run mode (for testing)
        if [[ "$SINGLE_RUN" == "true" ]]; then
            log_supervisor "INFO" "Single run mode, exiting"
            break
        fi

        # Check for shutdown before sleep
        if [[ "$SHUTDOWN_REQUESTED" == "true" ]]; then
            break
        fi

        # Determine sleep time: normal interval or backoff
        local sleep_time=$WATCH_INTERVAL
        if (( CONSECUTIVE_FAILURES > 0 )); then
            sleep_time=$CURRENT_BACKOFF
        fi

        # Calculate actual sleep accounting for cycle duration
        local cycle_duration=$(($(date +%s) - cycle_start))
        local adjusted_sleep=$((sleep_time - cycle_duration))
        if (( adjusted_sleep < 1 )); then
            adjusted_sleep=1
        fi

        # Perform interruptible sleep with heartbeats
        perform_backoff_sleep "$adjusted_sleep"
    done

    log_supervisor "INFO" "Main loop exited"
}

# =============================================================================
# MAIN ENTRY POINT
# =============================================================================
main() {
    local command="${1:-daemon}"

    case "$command" in
        daemon|start)
            run_daemon
            ;;

        once)
            # Run once and exit
            START_TIME=$(date +%s)
            log_supervisor "INFO" "Running single check cycle"
            SINGLE_RUN=true
            check_dep_requests || true  # Process DEP_REQUESTs first
            check_reviews || true  # Don't exit on error in once mode
            print_status
            ;;

        process)
            # Process a specific task
            shift
            local task_id="${1:-}"
            if [[ -z "$task_id" ]]; then
                echo "Usage: $0 process <task_id> [workspace]"
                exit 1
            fi
            local workspace="${2:-$AUTONOMOUS_ROOT}"
            process_task "$task_id" "$workspace"
            ;;

        status)
            # Show queue status
            START_TIME=$(date +%s)  # For uptime calculation
            CYCLE_COUNT=0
            print_status
            ;;

        health)
            # Check supervisor health
            if [[ -f "$HEARTBEAT_FILE" ]]; then
                local last_heartbeat
                last_heartbeat=$(cat "$HEARTBEAT_FILE" 2>/dev/null)
                echo "$last_heartbeat"

                # Check if heartbeat is recent (within 2x heartbeat interval)
                local heartbeat_epoch
                heartbeat_epoch=$(echo "$last_heartbeat" | grep -o '"epoch": [0-9]*' | grep -o '[0-9]*' || echo "0")
                local now
                now=$(date +%s)
                local age=$((now - heartbeat_epoch))

                if (( age > HEARTBEAT_INTERVAL * 2 )); then
                    echo ""
                    echo "WARNING: Heartbeat is stale (${age}s old)"
                    exit 1
                else
                    echo ""
                    echo "Supervisor is healthy (heartbeat ${age}s ago)"
                    exit 0
                fi
            else
                echo "No heartbeat file found - supervisor may not be running"
                exit 1
            fi
            ;;

        help|--help|-h)
            echo "tri-agent-supervisor v2.3.0 (M2-010 Unified + M2-011 Crash-Resistant + P0-5 DEP_REQUEST)"
            echo ""
            echo "Usage: $0 [command]"
            echo ""
            echo "Commands:"
            echo "  daemon, start   Run as daemon (default)"
            echo "  once            Run single check cycle and exit"
            echo "  process <id>    Process specific task"
            echo "  status          Show queue status"
            echo "  health          Check supervisor health via heartbeat"
            echo "  help            Show this help"
            echo ""
            echo "Environment Variables:"
            echo "  WATCH_INTERVAL           Seconds between checks (default: 30)"
            echo "  MAX_CONCURRENT           Max tasks per cycle (default: 3)"
            echo "  SINGLE_RUN               Exit after one cycle (default: false)"
            echo "  VERBOSE                  Enable debug logging (default: false)"
            echo ""
            echo "M2-011 Crash-Resistant Options:"
            echo "  INITIAL_BACKOFF          Initial backoff seconds (default: 1)"
            echo "  MAX_BACKOFF              Maximum backoff seconds (default: 300)"
            echo "  BACKOFF_MULTIPLIER       Exponential multiplier (default: 2)"
            echo "  HEARTBEAT_INTERVAL       Heartbeat interval seconds (default: 10)"
            echo "  MAX_CONSECUTIVE_FAILURES Max failures before degraded mode (default: 10)"
            echo "  COMPONENT_RESTART_DELAY  Delay before component restart (default: 5)"
            echo ""
            echo "P0-5 Dependency Request Options:"
            echo "  DEP_INSTALL_TIMEOUT      Dependency install timeout seconds (default: 120)"
            echo ""
            echo "Supported Dependency Types: npm, pip, pip3, apt, apt-get, cargo"
            echo ""
            echo "Files:"
            echo "  ${PID_FILE}              PID file"
            echo "  ${HEARTBEAT_FILE}        Heartbeat file (JSON)"
            echo "  ${STATE_FILE}            State file (JSON)"
            echo "  ${SUPERVISOR_INBOX}      DEP_REQUEST inbox"
            echo "  ${LOG_DIR}/supervisor.log    Log file"
            echo "  ${LOG_DIR}/dep-install.log   Dependency install log"
            echo ""
            ;;

        *)
            echo "Unknown command: $command"
            echo "Run '$0 help' for usage"
            exit 1
            ;;
    esac
}

# Run main
main "$@"
