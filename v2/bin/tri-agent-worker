#!/bin/bash
#===============================================================================
# tri-agent-worker - Autonomous SDLC Worker Agent (v2.0)
#===============================================================================
# Features:
# - M1-001: SQLite canonical task claiming with BEGIN IMMEDIATE transaction
# - M1-004: Signal-based worker pause/resume with graceful shutdown
# - P1-8:   Docker sandbox enforcement for delegate execution isolation
# - Atomic task claiming via sqlite_claim_task() (verified success)
# - Active governance via signals (SIGUSR1/SIGUSR2/SIGTERM/SIGINT)
# - Filesystem queue bridge (compatibility)
# - Worker sharding support
# - Budget watchdog integration
# - Robust JSON handling (jq/python fallback)
#
# Task Claiming (M1-001):
# - Uses BEGIN IMMEDIATE transaction for atomic claiming
# - Verifies UPDATE succeeded via changes() before returning task ID
# - Prevents race conditions where multiple workers claim the same task
# - Sets heartbeat_at and last_activity_at on claim for monitoring
#
# Signal-based Control (M1-004):
# - SIGUSR1: Pause worker (stop claiming new tasks, finish current)
# - SIGUSR2: Resume worker (resume task claiming)
# - SIGTERM: Graceful shutdown (wait for task completion, then exit)
# - SIGINT:  Immediate shutdown (release task, exit)
#
# State Machine (M1-004):
# - RUNNING: Normal operation, claiming and processing tasks
# - PAUSED:  Stopped claiming new tasks (via SIGUSR1 or budget watchdog)
# - STOPPING: Graceful shutdown in progress (waiting for task completion)
#
# Budget Watchdog Integration (M1-004):
# - Workers register PID with budget watchdog on startup
# - Budget watchdog sends SIGUSR1 when threshold exceeded
# - Workers complete current task and pause
# - Budget watchdog sends SIGUSR2 when budget replenished
#
# Docker Sandbox (P1-8):
# - Delegate execution runs in Docker container for isolation
# - Prevents untrusted task code from accessing host system
# - Configurable via DOCKER_SANDBOX_ENABLED (default: true)
# - Uses claude-sandbox:latest image (build from Dockerfile)
# - Security: no-new-privileges, cap-drop ALL, readonly root, network=none
# - Fallback: Bare metal execution if Docker unavailable
#===============================================================================

set -eo pipefail

# Resolve paths
SCRIPT_PATH="${BASH_SOURCE[0]}"
while [[ -L "$SCRIPT_PATH" ]]; do
    SCRIPT_DIR="$(cd -P "$(dirname "$SCRIPT_PATH")" && pwd)"
    SCRIPT_PATH="$(readlink "$SCRIPT_PATH")"
    [[ "$SCRIPT_PATH" != /* ]] && SCRIPT_PATH="$SCRIPT_DIR/$SCRIPT_PATH"
done
SCRIPT_DIR="$(cd -P "$(dirname "$SCRIPT_PATH")" && pwd)"
AUTONOMOUS_ROOT="${AUTONOMOUS_ROOT:-$(cd "${SCRIPT_DIR}/.." && pwd)}"

# Source common utilities
source "${AUTONOMOUS_ROOT}/lib/common.sh"

# Load worker configuration from tri-agent.yaml
_load_worker_config() {
    SQLITE_BUSY_TIMEOUT="${SQLITE_BUSY_TIMEOUT:-$(read_config '.error_handling.backoff_base' '30')}"
    SQLITE_BUSY_TIMEOUT=$((SQLITE_BUSY_TIMEOUT * 1000))
    SQLITE_MAX_RETRIES="${SQLITE_MAX_RETRIES:-$(read_config '.error_handling.max_retries' '10')}"
    WATCH_INTERVAL="${WATCH_INTERVAL:-$(read_config '.monitoring.health_check_interval' '30')}"
    log_info "Worker config loaded"
}
_load_worker_config

# Source security utilities (SEC-001: LLM Input Sanitization)
if [[ -f "${AUTONOMOUS_ROOT}/lib/security.sh" ]]; then
    source "${AUTONOMOUS_ROOT}/lib/security.sh"
else
    log_warn "lib/security.sh not found - some security functions unavailable"
fi

# Source SQLite State (Essential)
if [[ -f "${AUTONOMOUS_ROOT}/lib/sqlite-state.sh" ]]; then
    source "${AUTONOMOUS_ROOT}/lib/sqlite-state.sh"
else
    echo "ERROR: lib/sqlite-state.sh not found" >&2
    exit 1
fi

# Optional heartbeat helpers
if [[ -f "${AUTONOMOUS_ROOT}/lib/heartbeat.sh" ]]; then
    source "${AUTONOMOUS_ROOT}/lib/heartbeat.sh"
fi

# Priority queue with anti-starvation (P1-11)
if [[ -f "${AUTONOMOUS_ROOT}/lib/priority-queue.sh" ]]; then
    source "${AUTONOMOUS_ROOT}/lib/priority-queue.sh"
    PRIORITY_QUEUE_ENABLED=true
else
    PRIORITY_QUEUE_ENABLED=false
fi

# Source rate limiter for API cost control
if [[ -f "${AUTONOMOUS_ROOT}/lib/rate-limiter.sh" ]]; then
    source "${AUTONOMOUS_ROOT}/lib/rate-limiter.sh"
    RATE_LIMITER_ENABLED=true
    init_rate_limiter 2>/dev/null || true
    log_info "Rate limiter enabled"
else
    RATE_LIMITER_ENABLED=false
fi

# Check delegate rate limit before execution
check_delegate_rate_limit() {
    local model="$1"
    [[ "$RATE_LIMITER_ENABLED" != "true" ]] && return 0
    if ! check_model_rate_limit "$model" 2>/dev/null; then
        log_warn "Rate limit exceeded for $model"
        return 1
    fi
    return 0
}

# Config
WORKER_ID="${WORKER_ID:-worker-$$-$(date +%s)}"
WORKER_PID=$$
WORKER_SHARD="${WORKER_SHARD:-}" # If set, only claims tasks for this shard
WORKER_MODEL="${WORKER_MODEL:-}" # If set, only claims tasks for this model

# Directories
QUEUE_DIR="${AUTONOMOUS_ROOT}/tasks/queue"
RUNNING_DIR="${AUTONOMOUS_ROOT}/tasks/running"
REVIEW_DIR="${AUTONOMOUS_ROOT}/tasks/review"
FAILED_DIR="${AUTONOMOUS_ROOT}/tasks/failed"
COMPLETED_DIR="${AUTONOMOUS_ROOT}/tasks/completed"
EXECUTIONS_DIR="${AUTONOMOUS_ROOT}/state/executions"
WORKER_LOG="${AUTONOMOUS_ROOT}/logs/worker.log"

# State Tracking (M1-004)
# Valid states: RUNNING, PAUSED, STOPPING
WORKER_STATE="RUNNING"
CURRENT_TASK=""
TASK_START_TIME=""
SHUTDOWN_TIMEOUT=300  # 5 minutes max wait for task completion on shutdown
BUDGET_WATCHDOG_PID=""

# Legacy compatibility
WORKER_PAUSED=false

#===============================================================================
# Docker Sandbox Configuration (P1-8: Docker Sandbox Enforcement)
#===============================================================================
# When enabled, delegate execution runs inside a Docker container for isolation.
# This prevents untrusted task code from accessing the host system directly.
#
# Environment Variables:
#   DOCKER_SANDBOX_ENABLED - Enable/disable sandbox (default: true)
#   DOCKER_SANDBOX_IMAGE   - Docker image to use (default: claude-sandbox:latest)
#   DOCKER_SANDBOX_TIMEOUT - Max execution time in seconds (default: 3600)
#   DOCKER_SANDBOX_MEMORY  - Memory limit (default: 4g)
#   DOCKER_SANDBOX_CPUS    - CPU limit (default: 2)
#   DOCKER_SANDBOX_NETWORK - Network mode (default: none for isolation)
#   DOCKER_SANDBOX_READONLY- Mount workspace as readonly (default: false)
#   DOCKER_SANDBOX_WORKSPACE - Container workspace path (default: /workspace)
#===============================================================================

DOCKER_SANDBOX_ENABLED="${DOCKER_SANDBOX_ENABLED:-true}"
DOCKER_SANDBOX_IMAGE="${DOCKER_SANDBOX_IMAGE:-claude-sandbox:latest}"
DOCKER_SANDBOX_TIMEOUT="${DOCKER_SANDBOX_TIMEOUT:-3600}"
DOCKER_SANDBOX_MEMORY="${DOCKER_SANDBOX_MEMORY:-4g}"
DOCKER_SANDBOX_CPUS="${DOCKER_SANDBOX_CPUS:-2}"
DOCKER_SANDBOX_NETWORK="${DOCKER_SANDBOX_NETWORK:-none}"
DOCKER_SANDBOX_READONLY="${DOCKER_SANDBOX_READONLY:-false}"
DOCKER_SANDBOX_WORKSPACE="${DOCKER_SANDBOX_WORKSPACE:-/workspace}"

#===============================================================================
# SQLite Wrapper with Flock + Retry Logic (Database Locking Fix)
#===============================================================================
# Research shows busy_timeout doesn't help when transactions upgrade from
# read to write. The solution is application-level serialization using flock().
#
# Sources:
# - https://berthub.eu/articles/posts/a-brief-post-on-sqlite3-database-locked-despite-timeout/
# - https://tenthousandmeters.com/blog/sqlite-concurrent-writes-and-database-is-locked-errors/
#===============================================================================
SQLITE_BUSY_TIMEOUT="${SQLITE_BUSY_TIMEOUT:-30000}"  # 30 seconds
SQLITE_MAX_RETRIES="${SQLITE_MAX_RETRIES:-10}"
SQLITE_FLOCK_TIMEOUT="${SQLITE_FLOCK_TIMEOUT:-10}"   # 10 seconds per flock attempt
SQLITE_LOCK_FILE="${STATE_DB}.lock"

# Ensure lock file exists
mkdir -p "$(dirname "$SQLITE_LOCK_FILE")" 2>/dev/null || true
touch "$SQLITE_LOCK_FILE" 2>/dev/null || SQLITE_LOCK_FILE="/tmp/.tri-agent-sqlite.lock"
touch "$SQLITE_LOCK_FILE" 2>/dev/null || true

# Safe sqlite3 wrapper with flock serialization + retry logic
# This ensures only one process accesses SQLite at a time at the application level
#
# FIX: Silent flock failure issue
# Previously, `flock -w 10 200 2>/dev/null || true` silently ignored lock failures.
# Now we properly track flock acquisition and retry with exponential backoff.
_db_exec() {
    local sql="$1"
    local max_retries="${SQLITE_MAX_RETRIES:-10}"
    local flock_timeout="${SQLITE_FLOCK_TIMEOUT:-10}"
    local attempt=0
    local result=""
    local exit_code=0
    local flock_acquired=false

    while (( attempt < max_retries )); do
        ((attempt++))
        flock_acquired=false

        # Use flock for application-level serialization
        # We must track flock success separately to avoid silent failures
        # fd 200 is used for the lock file
        {
            # Try to acquire the lock with timeout
            if flock -w "$flock_timeout" 200 2>/dev/null; then
                flock_acquired=true
                # Lock acquired - execute SQL while holding the lock
                result=$(_sqlite_exec "$STATE_DB" "$sql" 2>&1) && exit_code=0 || exit_code=$?
            else
                # Flock failed to acquire lock within timeout
                flock_acquired=false
                exit_code=75  # EX_TEMPFAIL - temporary failure, caller should retry
            fi
        } 200>"$SQLITE_LOCK_FILE"

        # Handle flock acquisition failure
        if [[ "$flock_acquired" != "true" ]]; then
            log_warn "flock failed to acquire lock on $SQLITE_LOCK_FILE (attempt $attempt/$max_retries, timeout ${flock_timeout}s)"

            # Retry with exponential backoff + jitter for flock failure
            if (( attempt < max_retries )); then
                local delay jitter
                # Exponential backoff: 0.5, 2, 4.5, 8, 12.5... seconds
                delay=$(awk "BEGIN {printf \"%.2f\", 0.5 * $attempt * $attempt}" 2>/dev/null || echo "1")
                jitter=$(awk "BEGIN {srand(); printf \"%.2f\", rand() * 1.0}" 2>/dev/null || echo "0.5")
                local total_delay
                total_delay=$(awk "BEGIN {printf \"%.2f\", $delay + $jitter}" 2>/dev/null || echo "2")
                log_debug "flock retry backoff: sleeping ${total_delay}s before attempt $((attempt + 1))"
                sleep "$total_delay" 2>/dev/null || sleep 2
            fi
            continue
        fi

        # Lock was acquired - check SQL execution result
        if [[ $exit_code -eq 0 ]]; then
            echo "$result"
            return 0
        fi

        # Check if it's a SQLite locking error (can happen even with flock in edge cases)
        if ! echo "$result" | grep -qiE "database is locked|busy|Runtime error"; then
            # Non-locking error - don't retry
            echo "$result" >&2
            return $exit_code
        fi

        # SQLite locking error - retry with exponential backoff + jitter
        log_warn "SQLite locking error despite flock (attempt $attempt/$max_retries): ${result:0:100}"
        if (( attempt < max_retries )); then
            local delay jitter
            delay=$(awk "BEGIN {printf \"%.2f\", 0.2 * $attempt * $attempt}" 2>/dev/null || echo "1")
            jitter=$(awk "BEGIN {srand(); printf \"%.2f\", rand() * 0.5}" 2>/dev/null || echo "0.1")
            sleep "$(awk "BEGIN {printf \"%.2f\", $delay + $jitter}" 2>/dev/null || echo "1")" 2>/dev/null || sleep 1
        fi
    done

    # All retries exhausted
    if [[ "$flock_acquired" != "true" ]]; then
        log_error "flock acquisition failed after $max_retries attempts - database operations not serialized"
    else
        log_error "SQLite operation failed after $max_retries attempts: ${result:0:200}"
    fi
    echo "$result" >&2
    return 1
}

#===============================================================================
# Dependency Deadlock Resolution (Gap Analysis P0-5)
#===============================================================================
# Allows workers to request dependency installation from supervisor instead of
# just failing. This prevents deadlocks where tasks fail repeatedly due to
# missing dependencies.
#
# Message Types:
#   DEP_REQUEST  - Worker -> Supervisor: Request dependency installation
#   DEP_RESPONSE - Supervisor -> Worker: Dependency installation result
#
# Supported dependency types:
#   - npm (Node.js packages)
#   - pip/pip3 (Python packages)
#   - apt/apt-get (System packages)
#   - cargo (Rust crates)
#===============================================================================

DEP_REQUEST_ENABLED="${DEP_REQUEST_ENABLED:-true}"
DEP_REQUEST_MAX_RETRIES="${DEP_REQUEST_MAX_RETRIES:-2}"
DEP_REQUEST_TIMEOUT="${DEP_REQUEST_TIMEOUT:-120}"
SUPERVISOR_INBOX="${AUTONOMOUS_ROOT}/state/comms/supervisor/inbox"

# Common dependency failure patterns
DEP_FAILURE_PATTERNS=(
    "ModuleNotFoundError:"
    "ImportError:"
    "Cannot find module"
    "Module not found:"
    "No module named"
    "npm ERR! missing:"
    "pip.*No matching distribution"
    "cargo.*could not find.*crate"
    "error: unresolved import"
    "Package .* is not installed"
    "command not found:"
    "bash:.*not found"
)

# Detect if failure is due to missing dependencies
detect_dependency_failure() {
    local output_file="$1"

    if [[ ! -f "$output_file" ]]; then
        return 1
    fi

    for pattern in "${DEP_FAILURE_PATTERNS[@]}"; do
        if grep -q "$pattern" "$output_file" 2>/dev/null; then
            return 0
        fi
    done

    return 1
}

# Extract dependency info from failure output
extract_dependency_info() {
    local output_file="$1"
    local dep_type=""
    local dep_name=""

    # Try to extract Python module name
    if grep -qE "ModuleNotFoundError|No module named" "$output_file" 2>/dev/null; then
        dep_type="pip"
        dep_name=$(grep -oE "(ModuleNotFoundError|No module named).*'[^']+'" "$output_file" 2>/dev/null | head -1 | grep -oE "'[^']+'" | tr -d "'")
    # Try to extract npm module
    elif grep -qE "Cannot find module|Module not found:" "$output_file" 2>/dev/null; then
        dep_type="npm"
        dep_name=$(grep -oE "(Cannot find module|Module not found:).*'[^']+'" "$output_file" 2>/dev/null | head -1 | grep -oE "'[^']+'" | tr -d "'")
    # Try to extract command not found
    elif grep -qE "command not found:" "$output_file" 2>/dev/null; then
        dep_type="apt"
        dep_name=$(grep -oE "[^: ]+: command not found" "$output_file" 2>/dev/null | head -1 | cut -d: -f1)
    fi

    if [[ -n "$dep_type" && -n "$dep_name" ]]; then
        echo "{\"type\":\"$dep_type\",\"name\":\"$dep_name\"}"
        return 0
    fi

    return 1
}

# Request dependency installation from supervisor
request_dependency_install() {
    local task_id="$1"
    local dep_info="$2"

    if [[ "$DEP_REQUEST_ENABLED" != "true" ]]; then
        log_warn "DEP_REQUEST disabled, cannot request installation"
        return 1
    fi

    log_info "Requesting dependency installation: $dep_info"

    # Create request message
    local request_id="depreq_${task_id}_$(date +%s)"
    local request_file="${SUPERVISOR_INBOX}/${request_id}.json"

    mkdir -p "$SUPERVISOR_INBOX"

    cat > "$request_file" <<EOF
{
    "type": "DEP_REQUEST",
    "request_id": "$request_id",
    "task_id": "$task_id",
    "worker_id": "$WORKER_ID",
    "dependency": $dep_info,
    "timestamp": "$(date -Iseconds)",
    "timeout_sec": $DEP_REQUEST_TIMEOUT
}
EOF

    log_info "DEP_REQUEST submitted: $request_id"

    # Wait for response (polling)
    local response_file="${AUTONOMOUS_ROOT}/state/comms/worker/${WORKER_ID}/inbox/${request_id}_response.json"
    local wait_start=$(date +%s)
    local wait_end=$((wait_start + DEP_REQUEST_TIMEOUT))

    while (( $(date +%s) < wait_end )); do
        if [[ -f "$response_file" ]]; then
            local status
            status=$(jq -r '.status // "unknown"' "$response_file" 2>/dev/null || echo "unknown")

            if [[ "$status" == "installed" ]]; then
                log_info "DEP_REQUEST fulfilled: dependency installed"
                rm -f "$response_file"
                return 0
            elif [[ "$status" == "failed" ]]; then
                local reason
                reason=$(jq -r '.reason // "unknown"' "$response_file" 2>/dev/null || echo "unknown")
                log_error "DEP_REQUEST failed: $reason"
                rm -f "$response_file"
                return 1
            fi
        fi
        sleep 5
    done

    log_warn "DEP_REQUEST timeout after ${DEP_REQUEST_TIMEOUT}s"
    return 1
}

# Handle dependency failure with retry
handle_dependency_failure() {
    local task_id="$1"
    local output_file="$2"
    local retry_count="${3:-0}"

    if [[ "$DEP_REQUEST_ENABLED" != "true" ]]; then
        return 1
    fi

    if (( retry_count >= DEP_REQUEST_MAX_RETRIES )); then
        log_warn "Max dependency retries ($DEP_REQUEST_MAX_RETRIES) reached for $task_id"
        return 1
    fi

    local dep_info
    if dep_info=$(extract_dependency_info "$output_file"); then
        log_info "Detected dependency failure in $task_id: $dep_info"

        if request_dependency_install "$task_id" "$dep_info"; then
            log_info "Dependency installed, will retry task"
            return 0  # Retry the task
        fi
    fi

    return 1
}

#===============================================================================
# Governance & Signals (M1-004: Signal-based Worker Control)
#===============================================================================
# Signal Protocol:
#   SIGUSR1 - Pause worker (stop claiming new tasks, finish current)
#   SIGUSR2 - Resume worker (resume task claiming)
#   SIGTERM - Graceful shutdown (wait for task completion, then exit)
#   SIGINT  - Immediate shutdown (release task, exit)
#
# State Machine:
#   RUNNING -> PAUSED (via SIGUSR1)
#   PAUSED  -> RUNNING (via SIGUSR2)
#   RUNNING -> STOPPING (via SIGTERM)
#   PAUSED  -> STOPPING (via SIGTERM)
#   STOPPING -> exit (after task completion or timeout)
#
# Budget Watchdog Integration:
#   The budget watchdog sends SIGUSR1 when budget threshold is reached.
#   Worker will complete current task and pause, preventing budget overrun.
#===============================================================================

# Update worker state in SQLite
update_worker_state() {
    local new_status="$1"
    local reason="${2:-}"

    if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
        local esc_worker_id="${WORKER_ID//\'/\'\'}"
        local esc_reason="${reason//\'/\'\'}"

        _db_exec "
            UPDATE workers
            SET status='$new_status',
                last_heartbeat=datetime('now'),
                metadata=json_set(COALESCE(metadata,'{}'), '$.state_reason', '$esc_reason')
            WHERE worker_id='$esc_worker_id';
        " 2>/dev/null || true

        # Log state change event
        _db_exec "
            INSERT INTO events (task_id, event_type, actor, payload, trace_id)
            VALUES ('', 'WORKER_STATE_CHANGE', '$esc_worker_id',
                    json_object('from', '$WORKER_STATE', 'to', '$new_status', 'reason', '$esc_reason'),
                    '${TRACE_ID:-}');
        " 2>/dev/null || true
    fi
}

# Get current worker state (for external queries)
get_worker_state() {
    echo "$WORKER_STATE"
}

# SIGUSR1: Pause worker (stop claiming new tasks)
handle_pause() {
    if [[ "$WORKER_STATE" == "STOPPING" ]]; then
        log_warn "Worker $WORKER_ID: Ignoring PAUSE signal - already stopping"
        return
    fi

    log_warn "Worker $WORKER_ID received PAUSE signal (SIGUSR1)"
    WORKER_STATE="PAUSED"
    WORKER_PAUSED=true  # Legacy compatibility

    update_worker_state "paused" "SIGUSR1 received"

    if [[ -n "$CURRENT_TASK" ]]; then
        log_info "Worker $WORKER_ID: Will complete current task $CURRENT_TASK before pausing"
    else
        log_info "Worker $WORKER_ID: Paused immediately (no active task)"
    fi

    # Notify budget watchdog integration (if configured)
    if [[ -n "$BUDGET_WATCHDOG_PID" ]] && kill -0 "$BUDGET_WATCHDOG_PID" 2>/dev/null; then
        log_debug "Worker $WORKER_ID: Acknowledged pause to budget watchdog"
    fi
}

# SIGUSR2: Resume worker (resume task claiming)
handle_resume() {
    if [[ "$WORKER_STATE" == "STOPPING" ]]; then
        log_warn "Worker $WORKER_ID: Cannot resume - shutdown in progress"
        return
    fi

    log_info "Worker $WORKER_ID received RESUME signal (SIGUSR2)"
    WORKER_STATE="RUNNING"
    WORKER_PAUSED=false  # Legacy compatibility

    update_worker_state "idle" "SIGUSR2 received - resumed"
    log_info "Worker $WORKER_ID: Resumed and ready to claim tasks"
}

# SIGTERM: Graceful shutdown with task completion
handle_shutdown() {
    if [[ "$WORKER_STATE" == "STOPPING" ]]; then
        log_warn "Worker $WORKER_ID: Already stopping, ignoring duplicate SIGTERM"
        return
    fi

    log_info "Worker $WORKER_ID received SIGTERM - initiating graceful shutdown"
    WORKER_STATE="STOPPING"
    WORKER_PAUSED=true  # Prevent new task claims

    update_worker_state "stopping" "SIGTERM received - graceful shutdown"

    if [[ -n "$CURRENT_TASK" ]]; then
        log_info "Worker $WORKER_ID: Waiting for task $CURRENT_TASK to complete (timeout: ${SHUTDOWN_TIMEOUT}s)"

        local wait_start
        wait_start=$(date +%s)

        # Wait for task completion with timeout
        while [[ -n "$CURRENT_TASK" ]]; do
            local elapsed=$(( $(date +%s) - wait_start ))

            if (( elapsed >= SHUTDOWN_TIMEOUT )); then
                log_warn "Worker $WORKER_ID: Shutdown timeout reached. Task $CURRENT_TASK may be orphaned."
                # Mark task as interrupted for recovery
                if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
                    local esc_task_id="${CURRENT_TASK//\'/\'\'}"
                    _db_exec "
                        UPDATE tasks
                        SET metadata=json_set(COALESCE(metadata,'{}'),
                            '$.interrupted', 1,
                            '$.interrupted_at', datetime('now'),
                            '$.interrupted_by', '$WORKER_ID')
                        WHERE id='$esc_task_id';
                    " 2>/dev/null || true
                fi
                break
            fi

            log_debug "Worker $WORKER_ID: Waiting for task completion... (${elapsed}s/${SHUTDOWN_TIMEOUT}s)"
            sleep 2
        done

        if [[ -z "$CURRENT_TASK" ]]; then
            log_info "Worker $WORKER_ID: Task completed successfully before shutdown"
        fi
    else
        log_info "Worker $WORKER_ID: No active task, shutting down immediately"
    fi

    # Final cleanup
    graceful_cleanup
}

# SIGINT: Immediate shutdown (Ctrl+C)
handle_interrupt() {
    log_warn "Worker $WORKER_ID received SIGINT - immediate shutdown"
    WORKER_STATE="STOPPING"

    if [[ -n "$CURRENT_TASK" ]]; then
        log_warn "Worker $WORKER_ID: Task $CURRENT_TASK interrupted. Releasing lock."

        # Release the task back to queue for another worker to pick up
        if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
            local esc_task_id="${CURRENT_TASK//\'/\'\'}"
            _db_exec "
                UPDATE tasks
                SET status='QUEUED',
                    claimed_by=NULL,
                    claimed_at=NULL,
                    metadata=json_set(COALESCE(metadata,'{}'),
                        '$.released_by', '$WORKER_ID',
                        '$.released_at', datetime('now'),
                        '$.release_reason', 'SIGINT')
                WHERE id='$esc_task_id' AND claimed_by='$WORKER_ID';
            " 2>/dev/null || true

            log_info "Worker $WORKER_ID: Task $CURRENT_TASK released back to queue"
        fi

        # Move file back to queue if it was moved to running
        local running_file="${RUNNING_DIR}/${CURRENT_TASK}.md"
        if [[ -f "$running_file" ]]; then
            mv "$running_file" "${QUEUE_DIR}/${CURRENT_TASK}.md" 2>/dev/null || true
        fi
    fi

    update_worker_state "terminated" "SIGINT received"
    immediate_cleanup
}

# Graceful cleanup (SIGTERM path)
graceful_cleanup() {
    log_info "Worker $WORKER_ID: Performing graceful cleanup..."

    # Kill heartbeat process
    if [[ -n "${HEARTBEAT_PID:-}" ]] && kill -0 "$HEARTBEAT_PID" 2>/dev/null; then
        kill "$HEARTBEAT_PID" 2>/dev/null || true
        wait "$HEARTBEAT_PID" 2>/dev/null || true
    fi

    # Update final state
    update_worker_state "terminated" "Graceful shutdown complete"

    # Remove worker registration
    if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
        local esc_worker_id="${WORKER_ID//\'/\'\'}"
        _db_exec "
            UPDATE workers
            SET status='offline',
                last_heartbeat=datetime('now')
            WHERE worker_id='$esc_worker_id';
        " 2>/dev/null || true
    fi

    # Clean up lock files
    local lock_dir="${RUNNING_DIR}/${CURRENT_TASK}.md.lock.d"
    if [[ -d "$lock_dir" ]]; then
        rm -rf "$lock_dir" 2>/dev/null || true
    fi

    log_info "Worker $WORKER_ID: Shutdown complete"
    exit 0
}

# Immediate cleanup (SIGINT path)
immediate_cleanup() {
    log_warn "Worker $WORKER_ID: Performing immediate cleanup..."

    # Kill heartbeat process
    if [[ -n "${HEARTBEAT_PID:-}" ]] && kill -0 "$HEARTBEAT_PID" 2>/dev/null; then
        kill -9 "$HEARTBEAT_PID" 2>/dev/null || true
    fi

    # Update final state
    if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
        local esc_worker_id="${WORKER_ID//\'/\'\'}"
        _db_exec "
            UPDATE workers
            SET status='offline'
            WHERE worker_id='$esc_worker_id';
        " 2>/dev/null || true
    fi

    log_warn "Worker $WORKER_ID: Immediate shutdown complete"
    exit 1
}

# Legacy cleanup function (for backwards compatibility)
cleanup() {
    graceful_cleanup
}

# Register signal handlers
trap handle_pause SIGUSR1
trap handle_resume SIGUSR2
trap handle_shutdown SIGTERM
trap handle_interrupt SIGINT

#===============================================================================
# Budget Watchdog Integration (M1-004)
#===============================================================================
# The budget watchdog monitors API costs and sends SIGUSR1 to pause workers
# when thresholds are exceeded. Workers acknowledge the pause and can be
# resumed via SIGUSR2 when budget is replenished.
#===============================================================================

# Check if budget watchdog has flagged a pause
check_budget_watchdog() {
    if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
        local budget_pause
        budget_pause=$(state_get "budget" "pause_workers" "0" 2>/dev/null || echo "0")

        if [[ "$budget_pause" == "1" && "$WORKER_STATE" == "RUNNING" ]]; then
            log_warn "Worker $WORKER_ID: Budget watchdog requests pause"
            handle_pause
            return 0
        fi
    fi
    return 1
}

# Register with budget watchdog (if running)
register_with_budget_watchdog() {
    local watchdog_pid_file="${AUTONOMOUS_ROOT}/state/budget-watchdog.pid"

    if [[ -f "$watchdog_pid_file" ]]; then
        BUDGET_WATCHDOG_PID=$(cat "$watchdog_pid_file" 2>/dev/null || echo "")

        if [[ -n "$BUDGET_WATCHDOG_PID" ]] && kill -0 "$BUDGET_WATCHDOG_PID" 2>/dev/null; then
            log_debug "Worker $WORKER_ID: Registered with budget watchdog (PID: $BUDGET_WATCHDOG_PID)"

            # Register worker PID for watchdog to signal
            if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
                _db_exec "
                    UPDATE workers
                    SET metadata=json_set(COALESCE(metadata,'{}'), '$.budget_watchdog_registered', 1)
                    WHERE worker_id='$WORKER_ID';
                " 2>/dev/null || true
            fi
        else
            BUDGET_WATCHDOG_PID=""
        fi
    fi
}

# Report current state for monitoring
report_worker_status() {
    cat <<EOF
{
  "worker_id": "$WORKER_ID",
  "pid": $WORKER_PID,
  "state": "$WORKER_STATE",
  "current_task": "${CURRENT_TASK:-null}",
  "task_start_time": "${TASK_START_TIME:-null}",
  "shard": "${WORKER_SHARD:-any}",
  "model": "${WORKER_MODEL:-any}",
  "budget_watchdog_pid": "${BUDGET_WATCHDOG_PID:-null}"
}
EOF
}

#===============================================================================
# Queue Bridge (File -> SQLite)
#===============================================================================

# Scan filesystem queue and register tasks in SQLite
scan_queue_dirs() {
    # Check root queue and priority subdirs
    for priority in CRITICAL HIGH MEDIUM LOW; do
        local dirs=("$QUEUE_DIR" "$QUEUE_DIR/$priority")
        
        for dir in "${dirs[@]}"; do
            [[ -d "$dir" ]] || continue
            
            # Use find to list .md files
            while IFS= read -r file; do
                [[ -f "$file" ]] || continue
                
                local filename
                filename=$(basename "$file")
                local task_id="${filename%.md}"
                
                # Register in SQLite (idempotent)
                # We assume priority based on dir or filename prefix
                local effective_priority="$priority"
                if [[ "$filename" =~ ^(CRITICAL|HIGH|MEDIUM|LOW)_ ]]; then
                    effective_priority="${BASH_REMATCH[1]}"
                fi
                
                ensure_task_exists "$task_id" "$effective_priority" "QUEUED"
                
            done < <(find "$dir" -maxdepth 1 -name "*.md" 2>/dev/null)
        done
    done
}

#===============================================================================
# Task Claiming (M1-001: SQLite Canonical Claiming)
#===============================================================================
# Uses sqlite_claim_task() from lib/sqlite-state.sh for atomic task claiming.
# The claim uses BEGIN IMMEDIATE transaction to ensure atomicity.
# Only returns task ID if the claim actually succeeded (verified via changes()).
#===============================================================================

acquire_task_lock() {
    # M1-001: Use SQLite atomic claim (canonical state)
    # sqlite_claim_task() uses BEGIN IMMEDIATE transaction and verifies
    # the UPDATE succeeded before returning the task ID
    local task_id
    task_id=$(sqlite_claim_task "$WORKER_ID" "" "$WORKER_SHARD" "$WORKER_MODEL")

    if [[ -n "$task_id" ]]; then
        CURRENT_TASK="$task_id"

        # Extract priority from task metadata (from SQLite) - using safe wrapper
        local task_priority=""
        if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
            task_priority=$(_db_exec "SELECT CASE priority WHEN 0 THEN 'CRITICAL' WHEN 1 THEN 'HIGH' WHEN 2 THEN 'MEDIUM' WHEN 3 THEN 'LOW' ELSE 'MEDIUM' END FROM tasks WHERE id='${task_id//\'/\'\'}' LIMIT 1;" 2>/dev/null || echo "MEDIUM")
        fi

        log_info "M1-001: Claimed task $task_id via SQLite atomic transaction (worker: $WORKER_ID, shard: ${WORKER_SHARD:-any}, model: ${WORKER_MODEL:-any}, priority: $task_priority)"

        # M1-001: Log claim event for audit trail - using safe wrapper
        if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
            local esc_task_id="${task_id//\'/\'\'}"
            local esc_worker_id="${WORKER_ID//\'/\'\'}"
            _db_exec "INSERT INTO events (task_id, event_type, actor, payload, trace_id) VALUES ('${esc_task_id}', 'TASK_CLAIMED', '${esc_worker_id}', 'M1-001: Atomic SQLite claim', '${TRACE_ID:-}');" 2>/dev/null || true
        fi

        # Sync file state for legacy compatibility
        # Find task file in queue and move to running
        local task_file=""
        local possible_files=(
            "$QUEUE_DIR/$task_id.md"
            "$QUEUE_DIR/CRITICAL/$task_id.md"
            "$QUEUE_DIR/HIGH/$task_id.md"
            "$QUEUE_DIR/MEDIUM/$task_id.md"
            "$QUEUE_DIR/LOW/$task_id.md"
        )

        for f in "${possible_files[@]}"; do
            if [[ -f "$f" ]]; then
                task_file="$f"
                break
            fi
        done

        if [[ -n "$task_file" && -f "$task_file" ]]; then
            local running_file="${RUNNING_DIR}/$(basename "$task_file")"
            mkdir -p "$RUNNING_DIR"
            mv "$task_file" "$running_file" 2>/dev/null || true
            log_debug "Synced file state: $task_file -> $running_file"
        fi

        # Create legacy lock directory for backwards compatibility
        local lock_dir="${RUNNING_DIR}/${task_id}.md.lock.d"
        mkdir -p "$lock_dir" 2>/dev/null || true
        echo "$WORKER_ID" > "$lock_dir/worker_id" 2>/dev/null || true
        echo "$(date -Iseconds)" > "$lock_dir/claimed_at" 2>/dev/null || true

        log_debug "Created legacy lock: $lock_dir"

        echo "$task_id"
        return 0
    fi

    CURRENT_TASK=""
    return 1
}

#===============================================================================
# Docker Sandbox Execution (P1-8: Docker Sandbox Enforcement)
#===============================================================================
# Wraps delegate execution in a Docker container for security isolation.
# Prevents untrusted task code from accessing host system directly.
#===============================================================================

# Check if Docker is available and sandbox image exists
check_docker_sandbox_available() {
    if ! command -v docker &>/dev/null; then
        log_warn "Docker not found - sandbox disabled"
        return 1
    fi

    # Check if image exists (don't pull automatically for security)
    if ! docker image inspect "$DOCKER_SANDBOX_IMAGE" &>/dev/null; then
        log_warn "Docker sandbox image '$DOCKER_SANDBOX_IMAGE' not found - build with: docker build -t $DOCKER_SANDBOX_IMAGE ."
        return 1
    fi

    return 0
}

# Run a command inside Docker sandbox
# Usage: run_in_sandbox <delegate_path> <content> <output_file> <exec_dir>
run_in_sandbox() {
    local delegate_path="$1"
    local content="$2"
    local output_file="$3"
    local exec_dir="$4"

    local delegate_name
    delegate_name=$(basename "$delegate_path")

    log_info "P1-8: Running delegate '$delegate_name' in Docker sandbox"

    # Build docker run command with security constraints
    local docker_args=(
        "run"
        "--rm"                                          # Remove container after exit
        "--name" "sandbox-${WORKER_ID}-$$"              # Unique container name
        "--memory" "$DOCKER_SANDBOX_MEMORY"             # Memory limit
        "--cpus" "$DOCKER_SANDBOX_CPUS"                 # CPU limit
        "--network" "$DOCKER_SANDBOX_NETWORK"           # Network isolation
        "--security-opt" "no-new-privileges:true"       # Prevent privilege escalation
        "--read-only"                                   # Read-only root filesystem
        "--tmpfs" "/tmp:rw,noexec,nosuid,size=512m"     # Writable tmp with size limit
        "--tmpfs" "/run:rw,noexec,nosuid,size=64m"      # Writable run
        "--user" "1000:1000"                            # Run as non-root user
        "--cap-drop" "ALL"                              # Drop all capabilities
        "--pids-limit" "256"                            # Limit process count
    )

    # Mount workspace (readonly or rw based on config)
    if [[ "$DOCKER_SANDBOX_READONLY" == "true" ]]; then
        docker_args+=("-v" "${AUTONOMOUS_ROOT}:${DOCKER_SANDBOX_WORKSPACE}:ro")
    else
        docker_args+=("-v" "${AUTONOMOUS_ROOT}:${DOCKER_SANDBOX_WORKSPACE}:rw")
    fi

    # Mount execution output directory for results
    docker_args+=("-v" "${exec_dir}:/output:rw")

    # Mount delegate script (readonly)
    docker_args+=("-v" "${delegate_path}:${DOCKER_SANDBOX_WORKSPACE}/bin/${delegate_name}:ro")

    # Environment variables
    docker_args+=("-e" "AUTONOMOUS_ROOT=${DOCKER_SANDBOX_WORKSPACE}")
    docker_args+=("-e" "WORKER_ID=${WORKER_ID}")
    docker_args+=("-e" "TASK_ID=${CURRENT_TASK}")
    docker_args+=("-e" "HOME=/tmp")

    # Add the image
    docker_args+=("$DOCKER_SANDBOX_IMAGE")

    # Command to run inside container
    # We use a wrapper to handle content safely via stdin
    docker_args+=("/bin/bash" "-c" "cat > /tmp/task_content.txt && ${DOCKER_SANDBOX_WORKSPACE}/bin/${delegate_name} < /tmp/task_content.txt > /output/output.txt 2>&1")

    # Execute with timeout
    local exit_code=0
    if timeout "${DOCKER_SANDBOX_TIMEOUT}s" docker "${docker_args[@]}" <<< "$content"; then
        exit_code=0
        log_info "P1-8: Sandbox execution completed successfully"
    else
        exit_code=$?
        if [[ $exit_code -eq 124 ]]; then
            log_error "P1-8: Sandbox execution timed out after ${DOCKER_SANDBOX_TIMEOUT}s"
            echo "ERROR: Sandbox execution timed out after ${DOCKER_SANDBOX_TIMEOUT}s" >> "$output_file"
        else
            log_warn "P1-8: Sandbox execution failed with exit code $exit_code"
        fi
    fi

    # Copy output from exec_dir if needed (already written to /output/output.txt -> $exec_dir/output.txt)
    if [[ -f "${exec_dir}/output.txt" ]]; then
        cp "${exec_dir}/output.txt" "$output_file" 2>/dev/null || true
    fi

    return $exit_code
}

# Execute delegate with optional sandbox wrapping
# Usage: execute_delegate <delegate_path> <content> <output_file> <exec_dir>
execute_delegate() {
    local delegate_path="$1"
    local content="$2"
    local output_file="$3"
    local exec_dir="$4"

    # Check if sandbox is enabled and available
    if [[ "$DOCKER_SANDBOX_ENABLED" == "true" ]]; then
        if check_docker_sandbox_available; then
            # Run in sandbox
            run_in_sandbox "$delegate_path" "$content" "$output_file" "$exec_dir"
            return $?
        else
            log_warn "P1-8: Docker sandbox requested but unavailable - falling back to bare metal execution"
            log_warn "P1-8: Set DOCKER_SANDBOX_ENABLED=false to suppress this warning"
        fi
    fi

    # Bare metal execution (fallback or sandbox disabled)
    log_debug "Executing delegate directly (bare metal): $delegate_path"
    if "$delegate_path" <<< "$content" > "$output_file" 2>&1; then
        return 0
    else
        return $?
    fi
}

#===============================================================================
# Task Execution
#===============================================================================

process_task() {
    local task_id="$1"
    CURRENT_TASK="$task_id"
    TASK_START_TIME=$(date -Iseconds)
    log_info "Processing task: $task_id (started: $TASK_START_TIME)"

    # Update worker state to busy
    update_worker_state "busy" "Processing task $task_id"

    # 1. Locate file
    local task_file=""
    local possible_files=(
        "$RUNNING_DIR/$task_id.md"
        "$QUEUE_DIR/$task_id.md"
        "$QUEUE_DIR/CRITICAL/$task_id.md"
        "$QUEUE_DIR/HIGH/$task_id.md"
        "$QUEUE_DIR/MEDIUM/$task_id.md"
        "$QUEUE_DIR/LOW/$task_id.md"
    )
    
    for f in "${possible_files[@]}"; do
        if [[ -f "$f" ]]; then
            task_file="$f"
            break
        fi
    done

    if [[ -z "$task_file" ]]; then
        log_error "Task file not found for claimed task $task_id. Releasing."
        # Mark as FAILED in DB so it doesn't loop
        transition_task "$task_id" "FAILED" "File missing" "$WORKER_ID"
        CURRENT_TASK=""
        return
    fi

    # SEC-001: Validate task file before processing (size, binary check, null bytes)
    if declare -f validate_task_content >/dev/null 2>&1; then
        if ! validate_task_content "$task_file"; then
            log_error "SEC-001: Task file validation failed for $task_id. Marking as FAILED."
            transition_task "$task_id" "FAILED" "Security validation failed" "$WORKER_ID"
            mkdir -p "$FAILED_DIR"
            mv "$task_file" "$FAILED_DIR/$task_id.md" 2>/dev/null || true
            CURRENT_TASK=""
            return
        fi
        log_debug "SEC-001: Task file validated successfully: $task_file"
    else
        log_warn "SEC-001: validate_task_content not available, skipping file validation"
    fi

    # 2. Move file to RUNNING (filesystem reflection)
    mkdir -p "$RUNNING_DIR"
    local running_file="$RUNNING_DIR/$task_id.md"
    if [[ "$task_file" != "$running_file" ]]; then
        mv "$task_file" "$running_file"
    fi

    # 3. Create execution context
    local exec_id="${task_id}_$(date +%s)"
    local exec_dir="${EXECUTIONS_DIR}/${exec_id}"
    mkdir -p "$exec_dir"

    # 4. Route & Execute (Delegates)
    # Parse file content for routing
    local content
    content=$(cat "$running_file")

    # SEC-001: Sanitize content before passing to delegates to prevent prompt injection
    # Step 1: Check for prompt injection patterns (detection + logging)
    if declare -f check_prompt_injection >/dev/null 2>&1; then
        if ! check_prompt_injection "$content" "true"; then
            log_warn "SEC-001: Prompt injection patterns detected in task $task_id (will be filtered)"
        fi
    fi

    # Step 2: Apply sanitization (sanitize_llm_input from lib/common.sh)
    content=$(sanitize_llm_input "$content")

    # Step 3: Additional filtering via security.sh if available
    if declare -f filter_prompt_injection >/dev/null 2>&1; then
        content=$(filter_prompt_injection "$content")
    fi

    log_debug "SEC-001: Content sanitized for delegate (task: $task_id)"

    local model="claude" # Default

    if [[ "$WORKER_MODEL" != "" ]]; then
        model="$WORKER_MODEL"
    elif [[ $(wc -c <<< "$content") -gt 50000 ]]; then
        model="gemini"
    elif echo "$content" | grep -qE "implementation|feature|bugfix"; then
        model="codex"
    fi

    log_info "Routing task $task_id to model $model"

    # Execute Delegate (P1-8: Optionally in Docker sandbox)
    local result=""
    local exit_code=0
    local delegate_path="${AUTONOMOUS_ROOT}/bin/${model}-delegate"

    # Check rate limit before delegate execution
    if ! check_delegate_rate_limit "$model"; then
        log_warn "Rate limit exceeded for model $model, requeueing task $task_id"
        # Requeue the task for later processing
        transition_task "$task_id" "QUEUED" "Rate limited - requeueing" "$WORKER_ID" || true
        mv "$running_file" "$QUEUE_DIR/$task_id.md" 2>/dev/null || true
        CURRENT_TASK=""
        TASK_START_TIME=""
        if [[ "$WORKER_STATE" == "RUNNING" ]]; then
            update_worker_state "idle" "Rate limited - task requeued"
        fi
        # Sleep briefly to allow rate limit window to progress
        sleep 5
        return
    fi

    if [[ -x "$delegate_path" ]]; then
        # P1-8: Execute delegate with optional Docker sandbox
        # The execute_delegate function handles sandbox vs bare metal execution
        # based on DOCKER_SANDBOX_ENABLED configuration
        if execute_delegate "$delegate_path" "$content" "${exec_dir}/output.txt" "$exec_dir"; then
            result="SUCCESS"
            log_debug "Delegate execution completed successfully (sandbox=${DOCKER_SANDBOX_ENABLED})"
        else
            result="FAILURE"
            exit_code=1
            log_warn "Delegate execution failed (sandbox=${DOCKER_SANDBOX_ENABLED})"
        fi
    else
        log_warn "Delegate ${model}-delegate not found. Simulating success."
        echo "Simulated execution for $task_id" > "${exec_dir}/output.txt"
        result="SUCCESS"
    fi

    # 5. Handle Result
    local task_end_time
    task_end_time=$(date -Iseconds)
    local task_duration=""
    if [[ -n "$TASK_START_TIME" ]]; then
        local start_epoch end_epoch
        start_epoch=$(date -d "$TASK_START_TIME" +%s 2>/dev/null || echo "0")
        end_epoch=$(date -d "$task_end_time" +%s 2>/dev/null || echo "0")
        if (( start_epoch > 0 && end_epoch > 0 )); then
            task_duration="$((end_epoch - start_epoch))s"
        fi
    fi

    if [[ "$result" == "SUCCESS" ]]; then
        # Move to REVIEW
        mkdir -p "$REVIEW_DIR"
        
        # M1-FIX: Update DB first to prevent orphans
        if transition_task "$task_id" "REVIEW" "Execution complete" "$WORKER_ID"; then
            if mv "$running_file" "$REVIEW_DIR/$task_id.md"; then
                log_info "Task $task_id submitted for review (duration: ${task_duration:-unknown})"
                
                # Notify Supervisor (File-based trigger for now, until unified)
                # The unified supervisor will poll the DB or Review dir
            else
                log_error "Failed to move file for $task_id to REVIEW. Reverting DB state."
                transition_task "$task_id" "RUNNING" "File move failed" "$WORKER_ID" || true
            fi
        else
            log_error "Failed to transition task $task_id to REVIEW (DB Error). Moving to FAILED."
            mkdir -p "$FAILED_DIR"
            mv "$running_file" "$FAILED_DIR/$task_id.md"
            transition_task "$task_id" "FAILED" "DB Transition Error" "$WORKER_ID" || true
        fi
    else
        # Check for dependency failure before marking as FAILED (P0-5)
        local output_file="${exec_dir}/output.txt"
        local dep_retry_count=0

        # Try to get retry count from task metadata
        if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
            local esc_task_id="${task_id//\'/\'\'}"
            dep_retry_count=$(_db_exec "
                SELECT COALESCE(json_extract(metadata, '$.dep_retry_count'), 0)
                FROM tasks WHERE id='$esc_task_id';
            " 2>/dev/null || echo "0")
            dep_retry_count=${dep_retry_count:-0}
        fi

        # P0-5: Check if this is a dependency failure that can be resolved
        if detect_dependency_failure "$output_file"; then
            log_info "Detected dependency failure for task $task_id (retry $dep_retry_count)"

            if handle_dependency_failure "$task_id" "$output_file" "$dep_retry_count"; then
                # Dependency was installed, retry the task
                log_info "Dependency installed, requeueing task $task_id for retry"

                # Update retry count
                local new_retry_count=$((dep_retry_count + 1))
                if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
                    local esc_task_id="${task_id//\'/\'\'}"
                    _db_exec "
                        UPDATE tasks
                        SET state='QUEUED',
                            worker_id=NULL,
                            metadata=json_set(COALESCE(metadata,'{}'), '$.dep_retry_count', $new_retry_count)
                        WHERE id='$esc_task_id';
                    " 2>/dev/null || true
                fi

                # Move file back to queue
                mv "$running_file" "$QUEUE_DIR/$task_id.md"
                log_info "Task $task_id requeued after dependency install"

                # Clear task tracking and return (don't mark as failed)
                CURRENT_TASK=""
                TASK_START_TIME=""
                if [[ "$WORKER_STATE" == "RUNNING" ]]; then
                    update_worker_state "idle" "Task $task_id requeued for dep retry"
                fi
                return
            fi
        fi

        # Move to FAILED (no dependency resolution possible)
        mkdir -p "$FAILED_DIR"

        # M1-FIX: Update DB first
        if transition_task "$task_id" "FAILED" "Delegate execution failed" "$WORKER_ID"; then
            mv "$running_file" "$FAILED_DIR/$task_id.md"
        else
            log_error "Failed to transition task $task_id to FAILED (DB Error). Moving file anyway."
            mv "$running_file" "$FAILED_DIR/$task_id.md"
        fi
        log_error "Task $task_id failed (duration: ${task_duration:-unknown})"
    fi

    # Clear task tracking
    CURRENT_TASK=""
    TASK_START_TIME=""

    # Update worker state back to idle (unless stopping/paused)
    if [[ "$WORKER_STATE" == "RUNNING" ]]; then
        update_worker_state "idle" "Task $task_id completed"
    fi
}

#===============================================================================
# Heartbeat Loop (M1-004 Enhanced)
#===============================================================================

heartbeat_loop() {
    while true; do
        # Determine current status based on state machine
        local heartbeat_status="idle"
        case "$WORKER_STATE" in
            RUNNING)
                if [[ -n "$CURRENT_TASK" ]]; then
                    heartbeat_status="busy"
                else
                    heartbeat_status="idle"
                fi
                ;;
            PAUSED)
                heartbeat_status="paused"
                ;;
            STOPPING)
                heartbeat_status="stopping"
                ;;
        esac

        if declare -F update_heartbeat_sqlite >/dev/null 2>&1; then
            update_heartbeat_sqlite "$WORKER_ID" "$heartbeat_status" "${CURRENT_TASK:-}"
        else
            local esc_worker_id="${WORKER_ID//\'/\'\'}"
            local esc_task="${CURRENT_TASK//\'/\'\'}"
            _db_exec "
                UPDATE workers
                SET last_heartbeat=datetime('now'),
                    status='$heartbeat_status',
                    current_task='$esc_task',
                    metadata=json_set(COALESCE(metadata,'{}'),
                        '$.state', '$WORKER_STATE',
                        '$.task_start_time', '${TASK_START_TIME:-}')
                WHERE worker_id='$esc_worker_id';
            " 2>/dev/null || true
        fi

        # Check if we should exit heartbeat loop (shutdown)
        if [[ "$WORKER_STATE" == "STOPPING" && -z "$CURRENT_TASK" ]]; then
            log_debug "Heartbeat loop: Worker stopping and no active task, exiting loop"
            break
        fi

        sleep 60
    done
}

#===============================================================================
# Main (M1-004: Signal-based Worker Control)
#===============================================================================

# Initialize DB if needed
sqlite_state_init "$STATE_DB"

# Register worker with enhanced metadata
_db_exec "
    INSERT OR REPLACE INTO workers (worker_id, pid, status, started_at, last_heartbeat, metadata)
    VALUES (
        '$WORKER_ID',
        $WORKER_PID,
        'starting',
        datetime('now'),
        datetime('now'),
        json_object(
            'state', 'RUNNING',
            'shard', '${WORKER_SHARD:-any}',
            'model', '${WORKER_MODEL:-any}',
            'shutdown_timeout', $SHUTDOWN_TIMEOUT
        )
    );
"

# Register with budget watchdog (M1-004)
register_with_budget_watchdog

# Start Heartbeat in background
heartbeat_loop &
HEARTBEAT_PID=$!

# Update EXIT trap to use graceful cleanup
trap 'graceful_cleanup' EXIT

log_info "Worker $WORKER_ID started (PID: $WORKER_PID, State: $WORKER_STATE, Shard: ${WORKER_SHARD:-any}, Model: ${WORKER_MODEL:-any})"

# Update status to running
update_worker_state "idle" "Worker started and ready"

# P1-11: Anti-starvation cycle counter
# pq_escalate_waiting() is called every ANTI_STARVATION_INTERVAL cycles
ANTI_STARVATION_INTERVAL="${ANTI_STARVATION_INTERVAL:-10}"
ANTI_STARVATION_CYCLE_COUNT=0

while true; do
    # 1. Check Worker State Machine (M1-004)
    case "$WORKER_STATE" in
        STOPPING)
            # Graceful shutdown in progress
            log_debug "Worker in STOPPING state, waiting for cleanup..."
            sleep 2
            continue
            ;;
        PAUSED)
            # Worker is paused (via SIGUSR1 or budget watchdog)
            log_debug "Worker paused (state: PAUSED). Waiting for resume signal..."
            sleep 5
            continue
            ;;
        RUNNING)
            # Normal operation, continue to task claiming
            ;;
        *)
            log_error "Unknown worker state: $WORKER_STATE. Resetting to RUNNING."
            WORKER_STATE="RUNNING"
            ;;
    esac

    # 2. Check Budget Watchdog (M1-004)
    # This handles both signal-based and SQLite-based pause requests
    if check_budget_watchdog; then
        # Budget watchdog triggered pause
        continue
    fi

    # 3. Check SQLite system pause state (Fallback/Legacy)
    if command -v sqlite3 &>/dev/null && [[ -f "$STATE_DB" ]]; then
        pause_flag=$(state_get "system" "pause_requested" "0" 2>/dev/null || echo "0")
        if [[ "$pause_flag" == "1" ]]; then
            log_debug "System pause requested via SQLite. Waiting..."
            sleep 5
            continue
        fi
    fi

    # 3.5. P1-11: Anti-starvation - Periodic priority escalation
    # Promotes long-waiting tasks to prevent starvation:
    #   LOW -> MEDIUM after 1 hour
    #   MEDIUM -> HIGH after 30 minutes
    #   HIGH -> CRITICAL after 15 minutes
    ANTI_STARVATION_CYCLE_COUNT=$((ANTI_STARVATION_CYCLE_COUNT + 1))
    if [[ "$PRIORITY_QUEUE_ENABLED" == "true" ]] && \
       (( ANTI_STARVATION_CYCLE_COUNT >= ANTI_STARVATION_INTERVAL )); then
        log_debug "P1-11: Running anti-starvation escalation (cycle $ANTI_STARVATION_CYCLE_COUNT)"
        pq_escalate_waiting 2>/dev/null || true
        ANTI_STARVATION_CYCLE_COUNT=0
    fi

    # 4. Bridge Queue (Sync files to DB)
    if ! scan_queue_dirs; then
        log_warn "Queue sync failed temporarily (DB busy?) - continuing"
    fi

    # 5. Claim Task (only if in RUNNING state)
    if [[ "$WORKER_STATE" == "RUNNING" ]]; then
        if task_id=$(acquire_task_lock); then
            process_task "$task_id"
        else
            # No tasks available, sleep with jitter to prevent thundering herd
            sleep $(( 5 + RANDOM % 5 ))
        fi
    fi
done
