# Tri-Agent Monitoring Dashboards

Grafana dashboards and Prometheus alert rules for observing the tri-agent system (Claude, Codex, Gemini).

## Directory Structure

```
dashboards/
├── grafana/
│   ├── tri-agent-overview.json    # Main observability dashboard
│   └── cost-analysis.json         # Cost and budget monitoring
├── prometheus/
│   └── alerts.yml                 # Prometheus alerting rules
└── README.md                      # This file
```

## Prerequisites

- Prometheus 2.40+ with remote write capability
- Grafana 10.0+ with Prometheus data source configured
- Tri-agent metrics exporter running (see Metrics Exporter section)

## Quick Start

### 1. Configure Prometheus

Add the alert rules to your Prometheus configuration:

```yaml
# /etc/prometheus/prometheus.yml
rule_files:
  - "/home/aadel/.claude/dashboards/prometheus/alerts.yml"

scrape_configs:
  - job_name: "tri-agent"
    static_configs:
      - targets: ["localhost:9090"]
    scrape_interval: 15s
    metrics_path: /metrics
```

Reload Prometheus configuration:

```bash
# Using SIGHUP
kill -HUP $(pidof prometheus)

# Or using API (if enabled)
curl -X POST http://localhost:9090/-/reload
```

### 2. Import Grafana Dashboards

#### Option A: Via Grafana UI

1. Open Grafana (http://localhost:3000)
2. Navigate to Dashboards > Import
3. Upload JSON file or paste contents
4. Select Prometheus data source
5. Click Import

#### Option B: Via Grafana API

```bash
# Set your Grafana credentials
GRAFANA_URL="http://localhost:3000"
GRAFANA_API_KEY="your-api-key"

# Import overview dashboard
curl -X POST "$GRAFANA_URL/api/dashboards/db" \
  -H "Authorization: Bearer $GRAFANA_API_KEY" \
  -H "Content-Type: application/json" \
  -d @/home/aadel/.claude/dashboards/grafana/tri-agent-overview.json

# Import cost dashboard
curl -X POST "$GRAFANA_URL/api/dashboards/db" \
  -H "Authorization: Bearer $GRAFANA_API_KEY" \
  -H "Content-Type: application/json" \
  -d @/home/aadel/.claude/dashboards/grafana/cost-analysis.json
```

#### Option C: Via Grafana Provisioning

```yaml
# /etc/grafana/provisioning/dashboards/tri-agent.yml
apiVersion: 1
providers:
  - name: "tri-agent"
    orgId: 1
    folder: "Tri-Agent"
    type: file
    disableDeletion: false
    editable: true
    options:
      path: /home/aadel/.claude/dashboards/grafana
```

### 3. Verify Installation

```bash
# Check Prometheus rules loaded
curl -s http://localhost:9090/api/v1/rules | jq '.data.groups[].name'

# Check alerts configured
curl -s http://localhost:9090/api/v1/alerts | jq '.data.alerts | length'

# Check Grafana dashboards
curl -s "$GRAFANA_URL/api/search?query=tri-agent" \
  -H "Authorization: Bearer $GRAFANA_API_KEY" | jq '.[].title'
```

## Metrics Exporter

The dashboards expect metrics in Prometheus format. Configure the tri-agent to export metrics:

### Option A: File-based (Node Exporter Textfile Collector)

```bash
# Location for metrics file
METRICS_FILE="/var/lib/node_exporter/textfile_collector/tri_agent.prom"

# Example metrics format (generated by tri-agent)
cat > "$METRICS_FILE" << 'EOF'
# HELP tri_agent_tasks_total Total number of tasks by status
# TYPE tri_agent_tasks_total counter
tri_agent_tasks_total{status="completed"} 1234
tri_agent_tasks_total{status="failed"} 56
tri_agent_tasks_total{status="in_progress"} 3

# HELP tri_agent_active_agents Number of currently active agents
# TYPE tri_agent_active_agents gauge
tri_agent_active_agents 9

# HELP tri_agent_context_tokens_used Current context token usage by model
# TYPE tri_agent_context_tokens_used gauge
tri_agent_context_tokens_used{model="claude"} 145000
tri_agent_context_tokens_used{model="codex"} 285000
tri_agent_context_tokens_used{model="gemini"} 520000

# HELP tri_agent_cost_total Cumulative cost by model in USD
# TYPE tri_agent_cost_total counter
tri_agent_cost_total{model="claude_opus"} 45.50
tri_agent_cost_total{model="claude_sonnet"} 28.30
tri_agent_cost_total{model="codex"} 35.20
tri_agent_cost_total{model="gemini"} 12.80

# HELP tri_agent_session_duration_seconds Current session duration
# TYPE tri_agent_session_duration_seconds gauge
tri_agent_session_duration_seconds 3600
EOF
```

### Option B: HTTP Endpoint (Push Gateway or Custom Exporter)

```python
#!/usr/bin/env python3
# /home/aadel/.claude/scripts/metrics_exporter.py

from prometheus_client import start_http_server, Counter, Gauge, Histogram
import time
import json

# Define metrics
tasks_total = Counter('tri_agent_tasks_total', 'Total tasks', ['status'])
active_agents = Gauge('tri_agent_active_agents', 'Active agents')
context_tokens = Gauge('tri_agent_context_tokens_used', 'Context tokens', ['model'])
cost_total = Counter('tri_agent_cost_total', 'Cost in USD', ['model'])
request_duration = Histogram('tri_agent_request_duration_seconds', 'Request duration',
                             buckets=[0.1, 0.5, 1, 5, 10, 30, 60, 120])

def collect_metrics():
    """Read metrics from tri-agent state files"""
    state_file = "/home/aadel/.claude/metrics/current.json"
    try:
        with open(state_file) as f:
            data = json.load(f)

        # Update gauges
        active_agents.set(data.get('active_agents', 0))

        for model, tokens in data.get('context_tokens', {}).items():
            context_tokens.labels(model=model).set(tokens)

    except Exception as e:
        print(f"Error collecting metrics: {e}")

if __name__ == '__main__':
    start_http_server(9091)
    print("Metrics server started on :9091")
    while True:
        collect_metrics()
        time.sleep(15)
```

## Dashboard Panels

### Tri-Agent Overview Dashboard

| Panel                  | Description                             | Metric                                      |
| ---------------------- | --------------------------------------- | ------------------------------------------- |
| Active Agents          | Gauge showing current agent count (0-9) | `tri_agent_active_agents`                   |
| Agent Utilization      | Percentage of max agents in use         | `tri_agent_active_agents / 9`               |
| Error Rate             | Task failure percentage                 | `tri_agent_tasks_total{status="failed"}`    |
| Tasks Completed        | Counter of successful tasks             | `tri_agent_tasks_total{status="completed"}` |
| Budget Utilization     | Percentage of $420 monthly budget       | `tri_agent_cost_total / 420`                |
| Session Duration       | Current session uptime                  | `tri_agent_session_duration_seconds`        |
| Context Utilization    | Per-model context usage                 | `tri_agent_context_tokens_used`             |
| Token Usage            | Input/output tokens over time           | `tri_agent_tokens_total`                    |
| Verification Pass Rate | Two-key verification success rate       | `tri_agent_verification_total`              |

### Cost Analysis Dashboard

| Panel                | Description                     | Metric                            |
| -------------------- | ------------------------------- | --------------------------------- |
| Monthly Budget       | Gauge with 70/85/95% thresholds | `tri_agent_cost_total`            |
| Budget Remaining     | Dollars left this month         | `420 - sum(tri_agent_cost_total)` |
| Days Until Exhausted | Projected days of runway        | Calculated from daily rate        |
| Cost Distribution    | Pie chart by model              | `tri_agent_cost_total{model=...}` |
| Daily Cost           | Stacked bar by model            | `increase(...[1d])`               |
| Cumulative Cost      | Line with budget threshold      | Running total                     |
| Token Efficiency     | Tokens per dollar by model      | Tokens / cost ratio               |

## Alert Rules

### Error Alerts

| Alert                       | Severity | Condition                     | Action                      |
| --------------------------- | -------- | ----------------------------- | --------------------------- |
| TriAgentHighErrorRate       | Critical | >10% errors for 5m            | Investigate systemic issues |
| TriAgentElevatedErrorRate   | Warning  | >5% errors for 10m            | Monitor and investigate     |
| TriAgentConsecutiveFailures | Critical | 5+ failures, 0 success in 10m | Immediate investigation     |

### Budget Alerts

| Alert                   | Severity | Condition     | Action                   |
| ----------------------- | -------- | ------------- | ------------------------ |
| TriAgentBudget70Percent | Warning  | >=70% of $420 | Review spending          |
| TriAgentBudget85Percent | High     | >=85% of $420 | Pause non-critical tasks |
| TriAgentBudget95Percent | Critical | >=95% of $420 | Stop all new tasks       |

### Context Alerts

| Alert                           | Severity | Condition      | Action               |
| ------------------------------- | -------- | -------------- | -------------------- |
| TriAgentClaudeContextHigh       | Warning  | >80% of 200K   | Plan session refresh |
| TriAgentCodexContextHigh        | Warning  | >80% of 400K   | Plan session refresh |
| TriAgentGeminiContextHigh       | Warning  | >80% of 1M     | Plan session refresh |
| TriAgentContextOverflowImminent | Critical | >95% any model | Immediate refresh    |

### Health Alerts

| Alert                    | Severity | Condition      | Action               |
| ------------------------ | -------- | -------------- | -------------------- |
| TriAgentModelUnavailable | Critical | Model down >2m | Check API/creds      |
| TriAgentHighLatency      | Warning  | p95 >30s       | Investigate slowdown |
| TriAgentRateLimited      | Warning  | >5 hits in 5m  | Implement backoff    |

## Alertmanager Configuration

To route alerts appropriately, configure Alertmanager:

```yaml
# /etc/alertmanager/alertmanager.yml
global:
  resolve_timeout: 5m

route:
  group_by: ["alertname", "severity"]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: "default"
  routes:
    - match:
        severity: critical
      receiver: "critical-alerts"
      continue: true
    - match:
        budget_level: "95"
      receiver: "budget-critical"

receivers:
  - name: "default"
    webhook_configs:
      - url: "http://localhost:8080/webhook"

  - name: "critical-alerts"
    slack_configs:
      - api_url: "${SLACK_WEBHOOK_URL}"
        channel: "#ai-ops-critical"
        title: "{{ .CommonAnnotations.summary }}"
        text: "{{ .CommonAnnotations.description }}"

  - name: "budget-critical"
    email_configs:
      - to: "ahmed@example.com"
        subject: "Tri-Agent Budget Critical Alert"
```

## Customization

### Adding Custom Panels

1. Open the dashboard in Grafana
2. Click "Add" > "Visualization"
3. Configure the query using available metrics
4. Save and export updated JSON

### Modifying Alert Thresholds

Edit `/home/aadel/.claude/dashboards/prometheus/alerts.yml`:

```yaml
# Example: Change error rate threshold from 10% to 15%
- alert: TriAgentHighErrorRate
  expr: |
    (...) * 100 > 15  # Changed from 10
```

Reload Prometheus after changes:

```bash
curl -X POST http://localhost:9090/-/reload
```

## Troubleshooting

### No Data in Dashboards

1. Verify Prometheus is scraping metrics:

   ```bash
   curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets'
   ```

2. Check metrics exist:

   ```bash
   curl -s 'http://localhost:9090/api/v1/query?query=tri_agent_tasks_total' | jq
   ```

3. Verify Grafana data source configuration

### Alerts Not Firing

1. Check rule evaluation:

   ```bash
   curl -s http://localhost:9090/api/v1/rules | jq '.data.groups[].rules[].state'
   ```

2. Verify Alertmanager connectivity:
   ```bash
   curl -s http://localhost:9093/api/v2/status | jq '.cluster.status'
   ```

### Dashboard Import Errors

- Ensure JSON is valid: `jq . dashboard.json`
- Check Grafana version compatibility
- Verify data source UID matches your Prometheus instance

## Support

For issues with these dashboards:

1. Check this README for troubleshooting steps
2. Review Grafana/Prometheus logs
3. Consult the tri-agent documentation at `~/.claude/CLAUDE.md`

---

Ahmed Adel Bakr Alderai
